{"cells":[{"source":"# Import any packages you want to use here\n","metadata":{"executionTime":80,"lastSuccessfullyExecutedCode":"# Import any packages you want to use here\n"},"id":"7f26dd6a-20aa-4d19-8d3f-b8f64fba1821","cell_type":"code","execution_count":327,"outputs":[]},{"source":"##  Classification and Regression Trees","metadata":{},"id":"a0ac303b-ad44-4690-a9f0-a70619fcabc4","cell_type":"markdown"},{"source":"**Train your first classification tree**\n\nIn this exercise we'll work with the Wisconsin Breast Cancer Dataset from the UCI machine learning repository. We'll predict whether a tumor is malignant or benign based on two features: the mean radius of the tumor (radius_mean) and its mean number of concave points (concave points_mean).","metadata":{},"id":"540470d7-eb27-442b-b0d5-ab28b0a7da96","cell_type":"markdown"},{"source":"# Add your code snippets here\nimport pandas as pd\nwbs_df = pd.read_csv('wbc.csv')\nwbs_df.head()","metadata":{"executionTime":585,"lastSuccessfullyExecutedCode":"# Add your code snippets here\nimport pandas as pd\nwbs_df = pd.read_csv('wbc.csv')\nwbs_df.head()"},"id":"7869e914-9bb1-4f2d-a48b-5ab87e36e9b7","cell_type":"code","execution_count":328,"outputs":[{"output_type":"execute_result","execution_count":328,"data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"id","type":"integer"},{"name":"diagnosis","type":"string"},{"name":"radius_mean","type":"number"},{"name":"texture_mean","type":"number"},{"name":"perimeter_mean","type":"number"},{"name":"area_mean","type":"number"},{"name":"smoothness_mean","type":"number"},{"name":"compactness_mean","type":"number"},{"name":"concavity_mean","type":"number"},{"name":"concave points_mean","type":"number"},{"name":"symmetry_mean","type":"number"},{"name":"fractal_dimension_mean","type":"number"},{"name":"radius_se","type":"number"},{"name":"texture_se","type":"number"},{"name":"perimeter_se","type":"number"},{"name":"area_se","type":"number"},{"name":"smoothness_se","type":"number"},{"name":"compactness_se","type":"number"},{"name":"concavity_se","type":"number"},{"name":"concave points_se","type":"number"},{"name":"symmetry_se","type":"number"},{"name":"fractal_dimension_se","type":"number"},{"name":"radius_worst","type":"number"},{"name":"texture_worst","type":"number"},{"name":"perimeter_worst","type":"number"},{"name":"area_worst","type":"number"},{"name":"smoothness_worst","type":"number"},{"name":"compactness_worst","type":"number"},{"name":"concavity_worst","type":"number"},{"name":"concave points_worst","type":"number"},{"name":"symmetry_worst","type":"number"},{"name":"fractal_dimension_worst","type":"number"},{"name":"Unnamed: 32","type":"number"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":0,"id":842302,"diagnosis":"M","radius_mean":17.99,"texture_mean":10.38,"perimeter_mean":122.8,"area_mean":1001,"smoothness_mean":0.1184,"compactness_mean":0.2776,"concavity_mean":0.3001,"concave points_mean":0.1471,"symmetry_mean":0.2419,"fractal_dimension_mean":0.07871,"radius_se":1.095,"texture_se":0.9053,"perimeter_se":8.589,"area_se":153.4,"smoothness_se":0.006399,"compactness_se":0.04904,"concavity_se":0.05373,"concave points_se":0.01587,"symmetry_se":0.03003,"fractal_dimension_se":0.006193,"radius_worst":25.38,"texture_worst":17.33,"perimeter_worst":184.6,"area_worst":2019,"smoothness_worst":0.1622,"compactness_worst":0.6656,"concavity_worst":0.7119,"concave points_worst":0.2654,"symmetry_worst":0.4601,"fractal_dimension_worst":0.1189,"Unnamed: 32":null},{"index":1,"id":842517,"diagnosis":"M","radius_mean":20.57,"texture_mean":17.77,"perimeter_mean":132.9,"area_mean":1326,"smoothness_mean":0.08474,"compactness_mean":0.07864,"concavity_mean":0.0869,"concave points_mean":0.07017,"symmetry_mean":0.1812,"fractal_dimension_mean":0.05667,"radius_se":0.5435,"texture_se":0.7339,"perimeter_se":3.398,"area_se":74.08,"smoothness_se":0.005225,"compactness_se":0.01308,"concavity_se":0.0186,"concave points_se":0.0134,"symmetry_se":0.01389,"fractal_dimension_se":0.003532,"radius_worst":24.99,"texture_worst":23.41,"perimeter_worst":158.8,"area_worst":1956,"smoothness_worst":0.1238,"compactness_worst":0.1866,"concavity_worst":0.2416,"concave points_worst":0.186,"symmetry_worst":0.275,"fractal_dimension_worst":0.08902,"Unnamed: 32":null},{"index":2,"id":84300903,"diagnosis":"M","radius_mean":19.69,"texture_mean":21.25,"perimeter_mean":130,"area_mean":1203,"smoothness_mean":0.1096,"compactness_mean":0.1599,"concavity_mean":0.1974,"concave points_mean":0.1279,"symmetry_mean":0.2069,"fractal_dimension_mean":0.05999,"radius_se":0.7456,"texture_se":0.7869,"perimeter_se":4.585,"area_se":94.03,"smoothness_se":0.00615,"compactness_se":0.04006,"concavity_se":0.03832,"concave points_se":0.02058,"symmetry_se":0.0225,"fractal_dimension_se":0.004571,"radius_worst":23.57,"texture_worst":25.53,"perimeter_worst":152.5,"area_worst":1709,"smoothness_worst":0.1444,"compactness_worst":0.4245,"concavity_worst":0.4504,"concave points_worst":0.243,"symmetry_worst":0.3613,"fractal_dimension_worst":0.08758,"Unnamed: 32":null},{"index":3,"id":84348301,"diagnosis":"M","radius_mean":11.42,"texture_mean":20.38,"perimeter_mean":77.58,"area_mean":386.1,"smoothness_mean":0.1425,"compactness_mean":0.2839,"concavity_mean":0.2414,"concave points_mean":0.1052,"symmetry_mean":0.2597,"fractal_dimension_mean":0.09744,"radius_se":0.4956,"texture_se":1.156,"perimeter_se":3.445,"area_se":27.23,"smoothness_se":0.00911,"compactness_se":0.07458,"concavity_se":0.05661,"concave points_se":0.01867,"symmetry_se":0.05963,"fractal_dimension_se":0.009208,"radius_worst":14.91,"texture_worst":26.5,"perimeter_worst":98.87,"area_worst":567.7,"smoothness_worst":0.2098,"compactness_worst":0.8663,"concavity_worst":0.6869,"concave points_worst":0.2575,"symmetry_worst":0.6638,"fractal_dimension_worst":0.173,"Unnamed: 32":null},{"index":4,"id":84358402,"diagnosis":"M","radius_mean":20.29,"texture_mean":14.34,"perimeter_mean":135.1,"area_mean":1297,"smoothness_mean":0.1003,"compactness_mean":0.1328,"concavity_mean":0.198,"concave points_mean":0.1043,"symmetry_mean":0.1809,"fractal_dimension_mean":0.05883,"radius_se":0.7572,"texture_se":0.7813,"perimeter_se":5.438,"area_se":94.44,"smoothness_se":0.01149,"compactness_se":0.02461,"concavity_se":0.05688,"concave points_se":0.01885,"symmetry_se":0.01756,"fractal_dimension_se":0.005115,"radius_worst":22.54,"texture_worst":16.67,"perimeter_worst":152.2,"area_worst":1575,"smoothness_worst":0.1374,"compactness_worst":0.205,"concavity_worst":0.4,"concave points_worst":0.1625,"symmetry_worst":0.2364,"fractal_dimension_worst":0.07678,"Unnamed: 32":null}]},"total_rows":5,"truncation_type":null},"text/plain":"         id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n0    842302         M  ...                  0.11890          NaN\n1    842517         M  ...                  0.08902          NaN\n2  84300903         M  ...                  0.08758          NaN\n3  84348301         M  ...                  0.17300          NaN\n4  84358402         M  ...                  0.07678          NaN\n\n[5 rows x 33 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>fractal_dimension_mean</th>\n      <th>radius_se</th>\n      <th>texture_se</th>\n      <th>perimeter_se</th>\n      <th>area_se</th>\n      <th>smoothness_se</th>\n      <th>compactness_se</th>\n      <th>concavity_se</th>\n      <th>concave points_se</th>\n      <th>symmetry_se</th>\n      <th>fractal_dimension_se</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n      <th>Unnamed: 32</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842302</td>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>0.07871</td>\n      <td>1.0950</td>\n      <td>0.9053</td>\n      <td>8.589</td>\n      <td>153.40</td>\n      <td>0.006399</td>\n      <td>0.04904</td>\n      <td>0.05373</td>\n      <td>0.01587</td>\n      <td>0.03003</td>\n      <td>0.006193</td>\n      <td>25.38</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>842517</td>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>0.05667</td>\n      <td>0.5435</td>\n      <td>0.7339</td>\n      <td>3.398</td>\n      <td>74.08</td>\n      <td>0.005225</td>\n      <td>0.01308</td>\n      <td>0.01860</td>\n      <td>0.01340</td>\n      <td>0.01389</td>\n      <td>0.003532</td>\n      <td>24.99</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84300903</td>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>0.05999</td>\n      <td>0.7456</td>\n      <td>0.7869</td>\n      <td>4.585</td>\n      <td>94.03</td>\n      <td>0.006150</td>\n      <td>0.04006</td>\n      <td>0.03832</td>\n      <td>0.02058</td>\n      <td>0.02250</td>\n      <td>0.004571</td>\n      <td>23.57</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84348301</td>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>0.09744</td>\n      <td>0.4956</td>\n      <td>1.1560</td>\n      <td>3.445</td>\n      <td>27.23</td>\n      <td>0.009110</td>\n      <td>0.07458</td>\n      <td>0.05661</td>\n      <td>0.01867</td>\n      <td>0.05963</td>\n      <td>0.009208</td>\n      <td>14.91</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84358402</td>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>0.05883</td>\n      <td>0.7572</td>\n      <td>0.7813</td>\n      <td>5.438</td>\n      <td>94.44</td>\n      <td>0.011490</td>\n      <td>0.02461</td>\n      <td>0.05688</td>\n      <td>0.01885</td>\n      <td>0.01756</td>\n      <td>0.005115</td>\n      <td>22.54</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"wbs_df.columns","metadata":{"executionTime":45,"lastSuccessfullyExecutedCode":"wbs_df.columns"},"cell_type":"code","id":"9a4769d4-7c2d-4a0f-b260-69fb0e9f9c59","execution_count":329,"outputs":[{"output_type":"execute_result","execution_count":329,"data":{"text/plain":"Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n       'perimeter_worst', 'area_worst', 'smoothness_worst',\n       'compactness_worst', 'concavity_worst', 'concave points_worst',\n       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n      dtype='object')"},"metadata":{}}]},{"source":"X = wbs_df[['radius_mean', 'concave points_mean']]\ny = wbs_df['diagnosis'].astype('category').replace({'M': 1, 'B': 0})","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"X = wbs_df[['radius_mean', 'concave points_mean']]\ny = wbs_df['diagnosis'].astype('category').replace({'M': 1, 'B': 0})"},"cell_type":"code","id":"38684eca-3643-4ad5-9a72-d15c63ab676e","execution_count":330,"outputs":[]},{"source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.8, stratify =y, random_state=42)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","metadata":{"executionTime":44,"lastSuccessfullyExecutedCode":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.8, stratify =y, random_state=42)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape"},"cell_type":"code","id":"5b93e44e-b264-484f-9748-3792cdb165cf","execution_count":331,"outputs":[{"output_type":"execute_result","execution_count":331,"data":{"text/plain":"((113, 2), (456, 2), (113,), (456,))"},"metadata":{}}]},{"source":"# Import DecisionTreeClassifier from sklearn.tree\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Instantiate a DecisionTreeClassifier 'dt' with a maximum depth of 6\ndt = DecisionTreeClassifier(max_depth =6, random_state=42)\n\n# Fit dt to the training set\ndt.fit(X_train, y_train)\n\n# Predict test set labels\ny_pred = dt.predict(X_test)\nprint(y_pred[0:5])","metadata":{"executionTime":52,"lastSuccessfullyExecutedCode":"# Import DecisionTreeClassifier from sklearn.tree\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Instantiate a DecisionTreeClassifier 'dt' with a maximum depth of 6\ndt = DecisionTreeClassifier(max_depth =6, random_state=42)\n\n# Fit dt to the training set\ndt.fit(X_train, y_train)\n\n# Predict test set labels\ny_pred = dt.predict(X_test)\nprint(y_pred[0:5])"},"cell_type":"code","id":"30da4523-4af0-45c7-b3ad-5f8b30a7feb5","execution_count":332,"outputs":[{"output_type":"stream","name":"stdout","text":"[1 1 0 1 0]\n"}]},{"source":"**Evaluate the classification tree**\n\nNow we evaluate its performance on the test set. We'll do so using the accuracy metric which corresponds to the fraction of correct predictions made on the test set.","metadata":{},"cell_type":"markdown","id":"24bf0d2e-cd1c-42a0-a218-52cd38b83e79"},{"source":"# Import accuracy_score\nfrom sklearn.metrics import accuracy_score\n\n# Predict test set labels\ny_pred = dt.predict(X_test)\n\n# Compute test set accuracy  \nacc = accuracy_score(y_test, y_pred)\nprint(\"Test set accuracy: {:.2f}\".format(acc))","metadata":{"executionTime":41,"lastSuccessfullyExecutedCode":"# Import accuracy_score\nfrom sklearn.metrics import accuracy_score\n\n# Predict test set labels\ny_pred = dt.predict(X_test)\n\n# Compute test set accuracy  \nacc = accuracy_score(y_test, y_pred)\nprint(\"Test set accuracy: {:.2f}\".format(acc))"},"cell_type":"code","id":"1fcf6ed5-2ba7-4743-b0e8-98cf0f21edaf","execution_count":333,"outputs":[{"output_type":"stream","name":"stdout","text":"Test set accuracy: 0.90\n"}]},{"source":"**Using entropy as a criterion**\n\nWe'll train a classification tree on the Wisconsin Breast Cancer dataset using entropy and gini as an information criterion. We'll do so using all the 30 features in the dataset, which is split into 80% train and 20% test.","metadata":{},"cell_type":"markdown","id":"09dea2b4-1990-471c-a043-12a9c3f9ab47"},{"source":"X = wbs_df.drop(columns =['id', 'diagnosis', 'Unnamed: 32'], axis = 1)\ny = wbs_df['diagnosis'].astype('category').replace({'M': 1, 'B': 0})","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"X = wbs_df.drop(columns =['id', 'diagnosis', 'Unnamed: 32'], axis = 1)\ny = wbs_df['diagnosis'].astype('category').replace({'M': 1, 'B': 0})"},"cell_type":"code","id":"46b9e119-7a7f-4f31-a699-9e8ad0ad984d","execution_count":334,"outputs":[]},{"source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.8, stratify =y, random_state=42)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","metadata":{"executionTime":42,"lastSuccessfullyExecutedCode":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.8, stratify =y, random_state=42)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape"},"cell_type":"code","id":"fcbfe6b6-ee94-46a0-99d2-0fceaacaa855","execution_count":335,"outputs":[{"output_type":"execute_result","execution_count":335,"data":{"text/plain":"((113, 30), (456, 30), (113,), (456,))"},"metadata":{}}]},{"source":"# Import DecisionTreeClassifier from sklearn.tree\nfrom sklearn.tree import DecisionTreeClassifier\n# Instantiate dt_entropy, set 'entropy' as the information criterion\ndt_entropy = DecisionTreeClassifier(max_depth=8, criterion='entropy', random_state=1)\ndt_gini = DecisionTreeClassifier(max_depth=8, criterion='gini', random_state=1)\n\n# Fit dt_entropy to the training set\ndt_entropy.fit(X_train, y_train)\ndt_gini.fit(X_train, y_train)","metadata":{"executionTime":49,"lastSuccessfullyExecutedCode":"# Import DecisionTreeClassifier from sklearn.tree\nfrom sklearn.tree import DecisionTreeClassifier\n# Instantiate dt_entropy, set 'entropy' as the information criterion\ndt_entropy = DecisionTreeClassifier(max_depth=8, criterion='entropy', random_state=1)\ndt_gini = DecisionTreeClassifier(max_depth=8, criterion='gini', random_state=1)\n\n# Fit dt_entropy to the training set\ndt_entropy.fit(X_train, y_train)\ndt_gini.fit(X_train, y_train)"},"cell_type":"code","id":"a3f602ff-05c4-477a-94ae-3cd7b89e10ff","execution_count":336,"outputs":[{"output_type":"execute_result","execution_count":336,"data":{"text/plain":"DecisionTreeClassifier(max_depth=8, random_state=1)","text/html":"<style>#sk-container-id-22 {color: black;background-color: white;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=8, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" checked><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=8, random_state=1)</pre></div></div></div></div></div>"},"metadata":{}}]},{"source":"**Entropy vs Gini index**\n\nWe'll compare the test set accuracy of dt_entropy to the accuracy of tree named dt_gini. ","metadata":{},"cell_type":"markdown","id":"15ffd3bd-69af-4b43-ba3d-13ceef6d359e"},{"source":"# Import accuracy_score from sklearn.metrics\nfrom sklearn.metrics import accuracy_score\n\n# Use dt_entropy to predict test set labels\ny_pred_ent= dt_entropy.predict(X_test)\ny_pred_gini= dt_gini.predict(X_test)\n\n# Evaluate accuracy_entropy\naccuracy_entropy =accuracy_score(y_test, y_pred_ent)\naccuracy_gini =accuracy_score(y_test, y_pred_gini)\n\n# Print accuracy_entropy\nprint(f'Accuracy achieved by using entropy: {accuracy_entropy:.3f}')\n\n# Print accuracy_gini\nprint(f'Accuracy achieved by using the gini index: {accuracy_gini:.3f}')","metadata":{"executionTime":39,"lastSuccessfullyExecutedCode":"# Import accuracy_score from sklearn.metrics\nfrom sklearn.metrics import accuracy_score\n\n# Use dt_entropy to predict test set labels\ny_pred_ent= dt_entropy.predict(X_test)\ny_pred_gini= dt_gini.predict(X_test)\n\n# Evaluate accuracy_entropy\naccuracy_entropy =accuracy_score(y_test, y_pred_ent)\naccuracy_gini =accuracy_score(y_test, y_pred_gini)\n\n# Print accuracy_entropy\nprint(f'Accuracy achieved by using entropy: {accuracy_entropy:.3f}')\n\n# Print accuracy_gini\nprint(f'Accuracy achieved by using the gini index: {accuracy_gini:.3f}')"},"cell_type":"code","id":"ed57d424-c01d-4ae2-a4b1-d7e417258586","execution_count":337,"outputs":[{"output_type":"stream","name":"stdout","text":"Accuracy achieved by using entropy: 0.895\nAccuracy achieved by using the gini index: 0.897\n"}]},{"source":"Notice how the two models achieve almost the same accuracy. Most of the time, the gini index and entropy lead to the same results. The gini index is slightly faster to compute and is the default criterion used in the DecisionTreeClassifier model of scikit-lear","metadata":{},"cell_type":"markdown","id":"a594585b-a684-4f2b-b202-0d03905c2046"},{"source":"**Train your first regression tree**\n\nWe'll train a regression tree to predict the mpg (miles per gallon) consumption of cars in the auto-mpg dataset using all the six available features.\n","metadata":{},"cell_type":"markdown","id":"091c0a37-ed9c-4048-9030-6fdbcbdf7cb2"},{"source":"auto_df = pd.read_csv('auto.csv')\nauto_df.head()","metadata":{"executionTime":62,"lastSuccessfullyExecutedCode":"auto_df = pd.read_csv('auto.csv')\nauto_df.head()"},"cell_type":"code","id":"13f02c8a-11eb-4d22-84f2-1d66dac0c3df","execution_count":338,"outputs":[{"output_type":"execute_result","execution_count":338,"data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"mpg","type":"number"},{"name":"displ","type":"number"},{"name":"hp","type":"integer"},{"name":"weight","type":"integer"},{"name":"accel","type":"number"},{"name":"origin","type":"string"},{"name":"size","type":"number"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":0,"mpg":18,"displ":250,"hp":88,"weight":3139,"accel":14.5,"origin":"US","size":15},{"index":1,"mpg":9,"displ":304,"hp":193,"weight":4732,"accel":18.5,"origin":"US","size":20},{"index":2,"mpg":36.1,"displ":91,"hp":60,"weight":1800,"accel":16.4,"origin":"Asia","size":10},{"index":3,"mpg":18.5,"displ":250,"hp":98,"weight":3525,"accel":19,"origin":"US","size":15},{"index":4,"mpg":34.3,"displ":97,"hp":78,"weight":2188,"accel":15.8,"origin":"Europe","size":10}]},"total_rows":5,"truncation_type":null},"text/plain":"    mpg  displ   hp  weight  accel  origin  size\n0  18.0  250.0   88    3139   14.5      US  15.0\n1   9.0  304.0  193    4732   18.5      US  20.0\n2  36.1   91.0   60    1800   16.4    Asia  10.0\n3  18.5  250.0   98    3525   19.0      US  15.0\n4  34.3   97.0   78    2188   15.8  Europe  10.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mpg</th>\n      <th>displ</th>\n      <th>hp</th>\n      <th>weight</th>\n      <th>accel</th>\n      <th>origin</th>\n      <th>size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18.0</td>\n      <td>250.0</td>\n      <td>88</td>\n      <td>3139</td>\n      <td>14.5</td>\n      <td>US</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9.0</td>\n      <td>304.0</td>\n      <td>193</td>\n      <td>4732</td>\n      <td>18.5</td>\n      <td>US</td>\n      <td>20.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>36.1</td>\n      <td>91.0</td>\n      <td>60</td>\n      <td>1800</td>\n      <td>16.4</td>\n      <td>Asia</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18.5</td>\n      <td>250.0</td>\n      <td>98</td>\n      <td>3525</td>\n      <td>19.0</td>\n      <td>US</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>34.3</td>\n      <td>97.0</td>\n      <td>78</td>\n      <td>2188</td>\n      <td>15.8</td>\n      <td>Europe</td>\n      <td>10.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"Xa = auto_df.drop(['mpg', 'origin'], axis = 1)\nya = auto_df['mpg']","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"Xa = auto_df.drop(['mpg', 'origin'], axis = 1)\nya = auto_df['mpg']"},"cell_type":"code","id":"26bca3ad-db35-42dc-bcfc-2ba4c2f196a7","execution_count":339,"outputs":[]},{"source":"Xa_train, Xa_test, ya_train, ya_test = train_test_split(Xa, ya, test_size =0.8,  random_state=42)\nXa_train.shape, Xa_test.shape, ya_train.shape, ya_test.shape","metadata":{"executionTime":49,"lastSuccessfullyExecutedCode":"Xa_train, Xa_test, ya_train, ya_test = train_test_split(Xa, ya, test_size =0.8,  random_state=42)\nXa_train.shape, Xa_test.shape, ya_train.shape, ya_test.shape"},"cell_type":"code","id":"e0a3c595-861b-4b6a-b6f0-47714e8978da","execution_count":340,"outputs":[{"output_type":"execute_result","execution_count":340,"data":{"text/plain":"((78, 5), (314, 5), (78,), (314,))"},"metadata":{}}]},{"source":"# Import DecisionTreeRegressor from sklearn.tree\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Instantiate dt\ndt = DecisionTreeRegressor(max_depth=8,\n             min_samples_leaf=0.13,\n            random_state=3)\n\n# Fit dt to the training set\ndt.fit(Xa_train, ya_train)","metadata":{"executionTime":36,"lastSuccessfullyExecutedCode":"# Import DecisionTreeRegressor from sklearn.tree\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Instantiate dt\ndt = DecisionTreeRegressor(max_depth=8,\n             min_samples_leaf=0.13,\n            random_state=3)\n\n# Fit dt to the training set\ndt.fit(Xa_train, ya_train)"},"cell_type":"code","id":"ae8ba03a-ccfe-4722-9d3e-3d00fcc89cca","execution_count":341,"outputs":[{"output_type":"execute_result","execution_count":341,"data":{"text/plain":"DecisionTreeRegressor(max_depth=8, min_samples_leaf=0.13, random_state=3)","text/html":"<style>#sk-container-id-23 {color: black;background-color: white;}#sk-container-id-23 pre{padding: 0;}#sk-container-id-23 div.sk-toggleable {background-color: white;}#sk-container-id-23 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-23 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-23 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-23 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-23 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-23 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-23 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-23 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-23 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-23 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-23 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-23 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-23 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-23 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-23 div.sk-item {position: relative;z-index: 1;}#sk-container-id-23 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-23 div.sk-item::before, #sk-container-id-23 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-23 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-23 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-23 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-23 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-23 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-23 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-23 div.sk-label-container {text-align: center;}#sk-container-id-23 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-23 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-23\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=8, min_samples_leaf=0.13, random_state=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" checked><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=8, min_samples_leaf=0.13, random_state=3)</pre></div></div></div></div></div>"},"metadata":{}}]},{"source":"**Evaluate the regression tree**\n\nWe will evaluate the test set performance of dt using the Root Mean Squared Error (RMSE) metric. The RMSE of a model measures, on average, how much the model's predictions differ from the actual labels. The RMSE of a model can be obtained by computing the square root of the model's Mean Squared Error (MSE).","metadata":{},"cell_type":"markdown","id":"02fe8a3c-262e-4653-a9c5-8b4c00f807ef"},{"source":"# Import mean_squared_error from sklearn.metrics as MSE\nfrom sklearn.metrics import mean_squared_error as MSE\n\n# Compute y_pred\nya_pred_dt = dt.predict(Xa_test)\n\n# Compute mse_dt\nmse_dt = MSE(ya_test, ya_pred_dt)\n\n# Compute rmse_dt\nrmse_dt = mse_dt**(1/2)\n\n# Print rmse_dt\nprint(\"Test set RMSE of dt: {:.2f}\".format(rmse_dt))","metadata":{"executionTime":45,"lastSuccessfullyExecutedCode":"# Import mean_squared_error from sklearn.metrics as MSE\nfrom sklearn.metrics import mean_squared_error as MSE\n\n# Compute y_pred\nya_pred_dt = dt.predict(Xa_test)\n\n# Compute mse_dt\nmse_dt = MSE(ya_test, ya_pred_dt)\n\n# Compute rmse_dt\nrmse_dt = mse_dt**(1/2)\n\n# Print rmse_dt\nprint(\"Test set RMSE of dt: {:.2f}\".format(rmse_dt))"},"cell_type":"code","id":"6c0f0051-33e8-454c-990d-db1f8628f669","execution_count":342,"outputs":[{"output_type":"stream","name":"stdout","text":"Test set RMSE of dt: 4.37\n"}]},{"source":"**Linear regression vs regression tree**\n\nWe'll compare the test set RMSE of dt to that achieved by a linear regression model. We have already instantiated a linear regression model lr and trained it on the same dataset as dt.\n\nThe features matrix X_test, the array of labels y_test, the trained linear regression model lr, mean_squared_error function which was imported under the alias MSE and rmse_dt from the previous exercise are available in your workspace.","metadata":{},"cell_type":"markdown","id":"5c2a3f73-10fc-4f12-ac9e-d7a2b8b4a943"},{"source":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(Xa_train, ya_train)\ny_pred_lr = lr.predict(Xa_test)\nmse_lr = MSE(ya_test, y_pred_lr)\nrmse_lr = mse_lr**(1/2)\nprint(\"Test set RMSE of lr: {:.2f}\".format(rmse_lr))","metadata":{"executionTime":38,"lastSuccessfullyExecutedCode":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(Xa_train, ya_train)\ny_pred_lr = lr.predict(Xa_test)\nmse_lr = MSE(ya_test, y_pred_lr)\nrmse_lr = mse_lr**(1/2)\nprint(\"Test set RMSE of lr: {:.2f}\".format(rmse_lr))"},"cell_type":"code","id":"47b686e7-2db3-47d0-946c-30b46c4b76ac","execution_count":343,"outputs":[{"output_type":"stream","name":"stdout","text":"Test set RMSE of lr: 4.22\n"}]},{"source":"## The Bias-Variance Tradeoff","metadata":{},"cell_type":"markdown","id":"25d7ecd9-5502-4214-baa8-69d1855635d3"},{"source":"**Instantiate the model**\n\nWe'll diagnose the bias and variance problems of a regression tree. The regression tree we'll define  will be used to predict the mpg consumption of cars from the auto dataset using all available features.","metadata":{},"cell_type":"markdown","id":"6aa7f087-5748-4eee-8628-57d8c82fc4ea"},{"source":"# Import train_test_split from sklearn.model_selection\nfrom sklearn.model_selection import train_test_split\n\n# Split the data into 70% train and 30% test\nXa_train, Xa_test, ya_train, ya_test = train_test_split(Xa, ya, test_size=0.3, random_state=1)\n\n# Instantiate a DecisionTreeRegressor dt\ndt = DecisionTreeRegressor(max_depth =4, min_samples_leaf=0.26, random_state=1)","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Import train_test_split from sklearn.model_selection\nfrom sklearn.model_selection import train_test_split\n\n# Split the data into 70% train and 30% test\nXa_train, Xa_test, ya_train, ya_test = train_test_split(Xa, ya, test_size=0.3, random_state=1)\n\n# Instantiate a DecisionTreeRegressor dt\ndt = DecisionTreeRegressor(max_depth =4, min_samples_leaf=0.26, random_state=1)"},"cell_type":"code","id":"e53a05f2-032a-4776-98f8-a3cb01d1f074","execution_count":344,"outputs":[]},{"source":"**Evaluate the 10-fold CV error**\n\nWe'll evaluate the 10-fold CV Root Mean Squared Error (RMSE) achieved by the regression tree dt that  we instantiated. \n**Note that since cross_val_score has only the option of evaluating the negative MSEs, its output should be multiplied by negative one to obtain the MSEs. The CV RMSE can then be obtained by computing the square root of the average MSE.**","metadata":{},"cell_type":"markdown","id":"443626c2-9810-44e6-aa65-71df111d5220"},{"source":"from sklearn.model_selection import cross_val_score\n# Compute the array containing the 10-folds CV MSEs\nMSE_CV_scores = - cross_val_score(dt, Xa_train, ya_train, cv=10, \n                       scoring='neg_mean_squared_error',\n                       n_jobs=-1)\n\n# Compute the 10-folds CV RMSE\nRMSE_CV = (MSE_CV_scores.mean())**(1/2)\n\n# Print RMSE_CV\nprint('CV RMSE: {:.2f}'.format(RMSE_CV))","metadata":{"executionTime":38,"lastSuccessfullyExecutedCode":"from sklearn.model_selection import cross_val_score\n# Compute the array containing the 10-folds CV MSEs\nMSE_CV_scores = - cross_val_score(dt, Xa_train, ya_train, cv=10, \n                       scoring='neg_mean_squared_error',\n                       n_jobs=-1)\n\n# Compute the 10-folds CV RMSE\nRMSE_CV = (MSE_CV_scores.mean())**(1/2)\n\n# Print RMSE_CV\nprint('CV RMSE: {:.2f}'.format(RMSE_CV))"},"cell_type":"code","id":"725d6f0c-dbfe-4be3-b79d-16affd8c4522","execution_count":345,"outputs":[{"output_type":"stream","name":"stdout","text":"CV RMSE: 5.14\n"}]},{"source":"**Evaluate the training error**\n\nNote that in scikit-learn, the MSE of a model can be computed as follows:\n\nMSE_model = mean_squared_error(y_true, y_predicted)\nwhere we use the function mean_squared_error from the metrics module and pass it the true labels y_true as a first argument, and the predicted labels from the model y_predicted as a second argument.","metadata":{},"cell_type":"markdown","id":"52968c22-fbe0-4615-81c0-674efd251eee"},{"source":"# Import mean_squared_error from sklearn.metrics\nfrom sklearn.metrics import mean_squared_error\n\n# Fit dt to the training set\ndt.fit(Xa_train, ya_train)\n\n# Predict the labels of the training and test set\nya_pred_train = dt.predict(Xa_train)\nya_pred_test = dt.predict(Xa_test)\n\n# Evaluate the training and test set RMSE of dt\nRMSE_train = (mean_squared_error(ya_train, ya_pred_train))**(1/2)\nRMSE_test = (mean_squared_error(ya_test, ya_pred_test))**(1/2)\n\n# Print RMSE_train\nprint('Train RMSE: {:.2f}'.format(RMSE_train))\nprint(\"Test set RMSE: {:.2f}\".format(RMSE_test))","metadata":{"executionTime":34,"lastSuccessfullyExecutedCode":"# Import mean_squared_error from sklearn.metrics\nfrom sklearn.metrics import mean_squared_error\n\n# Fit dt to the training set\ndt.fit(Xa_train, ya_train)\n\n# Predict the labels of the training and test set\nya_pred_train = dt.predict(Xa_train)\nya_pred_test = dt.predict(Xa_test)\n\n# Evaluate the training and test set RMSE of dt\nRMSE_train = (mean_squared_error(ya_train, ya_pred_train))**(1/2)\nRMSE_test = (mean_squared_error(ya_test, ya_pred_test))**(1/2)\n\n# Print RMSE_train\nprint('Train RMSE: {:.2f}'.format(RMSE_train))\nprint(\"Test set RMSE: {:.2f}\".format(RMSE_test))"},"cell_type":"code","id":"fc5c047a-280e-45c7-aa64-baef86761dcc","execution_count":346,"outputs":[{"output_type":"stream","name":"stdout","text":"Train RMSE: 5.15\nTest set RMSE: 4.86\n"}]},{"source":"dt suffers from high bias because RMSE_CV and RMSE_train and both scores are greater than test set RMSE.","metadata":{},"cell_type":"markdown","id":"6e6962e7-d1ba-4415-8ad9-1f0330fb9563"},{"source":"## Ensemble Methods","metadata":{},"cell_type":"markdown","id":"6f00b485-46d2-4113-93fc-896e9fc03003"},{"source":"**Voting Classifier**\n\nWe'll work with the Indian Liver Patient Dataset from the UCI Machine learning repository.\n\nWe'll instantiate three classifiers to predict whether a patient suffers from a liver disease using all the features present in the dataset.","metadata":{},"cell_type":"markdown","id":"ca88a471-216b-40bd-9b42-95c2c0d97e58"},{"source":"liver_df = pd.read_csv('indian_liver_patient.csv')\nliver_df.head()","metadata":{"executionTime":50,"lastSuccessfullyExecutedCode":"liver_df = pd.read_csv('indian_liver_patient.csv')\nliver_df.head()"},"cell_type":"code","id":"8c46be49-745c-445f-bcc7-65a18b161395","execution_count":347,"outputs":[{"output_type":"execute_result","execution_count":347,"data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"Age","type":"integer"},{"name":"Gender","type":"string"},{"name":"Total_Bilirubin","type":"number"},{"name":"Direct_Bilirubin","type":"number"},{"name":"Alkaline_Phosphotase","type":"integer"},{"name":"Alamine_Aminotransferase","type":"integer"},{"name":"Aspartate_Aminotransferase","type":"integer"},{"name":"Total_Protiens","type":"number"},{"name":"Albumin","type":"number"},{"name":"Albumin_and_Globulin_Ratio","type":"number"},{"name":"Dataset","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":0,"Age":65,"Gender":"Female","Total_Bilirubin":0.7,"Direct_Bilirubin":0.1,"Alkaline_Phosphotase":187,"Alamine_Aminotransferase":16,"Aspartate_Aminotransferase":18,"Total_Protiens":6.8,"Albumin":3.3,"Albumin_and_Globulin_Ratio":0.9,"Dataset":1},{"index":1,"Age":62,"Gender":"Male","Total_Bilirubin":10.9,"Direct_Bilirubin":5.5,"Alkaline_Phosphotase":699,"Alamine_Aminotransferase":64,"Aspartate_Aminotransferase":100,"Total_Protiens":7.5,"Albumin":3.2,"Albumin_and_Globulin_Ratio":0.74,"Dataset":1},{"index":2,"Age":62,"Gender":"Male","Total_Bilirubin":7.3,"Direct_Bilirubin":4.1,"Alkaline_Phosphotase":490,"Alamine_Aminotransferase":60,"Aspartate_Aminotransferase":68,"Total_Protiens":7,"Albumin":3.3,"Albumin_and_Globulin_Ratio":0.89,"Dataset":1},{"index":3,"Age":58,"Gender":"Male","Total_Bilirubin":1,"Direct_Bilirubin":0.4,"Alkaline_Phosphotase":182,"Alamine_Aminotransferase":14,"Aspartate_Aminotransferase":20,"Total_Protiens":6.8,"Albumin":3.4,"Albumin_and_Globulin_Ratio":1,"Dataset":1},{"index":4,"Age":72,"Gender":"Male","Total_Bilirubin":3.9,"Direct_Bilirubin":2,"Alkaline_Phosphotase":195,"Alamine_Aminotransferase":27,"Aspartate_Aminotransferase":59,"Total_Protiens":7.3,"Albumin":2.4,"Albumin_and_Globulin_Ratio":0.4,"Dataset":1}]},"total_rows":5,"truncation_type":null},"text/plain":"   Age  Gender  Total_Bilirubin  ...  Albumin  Albumin_and_Globulin_Ratio  Dataset\n0   65  Female              0.7  ...      3.3                        0.90        1\n1   62    Male             10.9  ...      3.2                        0.74        1\n2   62    Male              7.3  ...      3.3                        0.89        1\n3   58    Male              1.0  ...      3.4                        1.00        1\n4   72    Male              3.9  ...      2.4                        0.40        1\n\n[5 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Gender</th>\n      <th>Total_Bilirubin</th>\n      <th>Direct_Bilirubin</th>\n      <th>Alkaline_Phosphotase</th>\n      <th>Alamine_Aminotransferase</th>\n      <th>Aspartate_Aminotransferase</th>\n      <th>Total_Protiens</th>\n      <th>Albumin</th>\n      <th>Albumin_and_Globulin_Ratio</th>\n      <th>Dataset</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>65</td>\n      <td>Female</td>\n      <td>0.7</td>\n      <td>0.1</td>\n      <td>187</td>\n      <td>16</td>\n      <td>18</td>\n      <td>6.8</td>\n      <td>3.3</td>\n      <td>0.90</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>62</td>\n      <td>Male</td>\n      <td>10.9</td>\n      <td>5.5</td>\n      <td>699</td>\n      <td>64</td>\n      <td>100</td>\n      <td>7.5</td>\n      <td>3.2</td>\n      <td>0.74</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>62</td>\n      <td>Male</td>\n      <td>7.3</td>\n      <td>4.1</td>\n      <td>490</td>\n      <td>60</td>\n      <td>68</td>\n      <td>7.0</td>\n      <td>3.3</td>\n      <td>0.89</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>58</td>\n      <td>Male</td>\n      <td>1.0</td>\n      <td>0.4</td>\n      <td>182</td>\n      <td>14</td>\n      <td>20</td>\n      <td>6.8</td>\n      <td>3.4</td>\n      <td>1.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>72</td>\n      <td>Male</td>\n      <td>3.9</td>\n      <td>2.0</td>\n      <td>195</td>\n      <td>27</td>\n      <td>59</td>\n      <td>7.3</td>\n      <td>2.4</td>\n      <td>0.40</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"liver_df = liver_df.dropna()\nprint(liver_df.isna().sum(), '\\n' , liver_df['Dataset'].value_counts())","metadata":{"executionTime":42,"lastSuccessfullyExecutedCode":"liver_df = liver_df.dropna()\nprint(liver_df.isna().sum(), '\\n' , liver_df['Dataset'].value_counts())"},"cell_type":"code","id":"b861757c-25e6-4646-a146-d00316c9baef","execution_count":348,"outputs":[{"output_type":"stream","name":"stdout","text":"Age                           0\nGender                        0\nTotal_Bilirubin               0\nDirect_Bilirubin              0\nAlkaline_Phosphotase          0\nAlamine_Aminotransferase      0\nAspartate_Aminotransferase    0\nTotal_Protiens                0\nAlbumin                       0\nAlbumin_and_Globulin_Ratio    0\nDataset                       0\ndtype: int64 \n 1    414\n2    165\nName: Dataset, dtype: int64\n"}]},{"source":"Xl =liver_df.drop('Dataset', axis =1)\nXl['Gender'] = Xl['Gender'].astype('category').replace({'Female' :0, 'Male': 1})\nyl =liver_df['Dataset']\nXl.shape, yl.shape","metadata":{"executionTime":33,"lastSuccessfullyExecutedCode":"Xl =liver_df.drop('Dataset', axis =1)\nXl['Gender'] = Xl['Gender'].astype('category').replace({'Female' :0, 'Male': 1})\nyl =liver_df['Dataset']\nXl.shape, yl.shape"},"cell_type":"code","id":"7654ebe5-ced9-4b0e-aa70-b1508e965fe8","execution_count":349,"outputs":[{"output_type":"execute_result","execution_count":349,"data":{"text/plain":"((579, 10), (579,))"},"metadata":{}}]},{"source":"# Split the data into 70% train and 30% test\nXl_train, Xl_test, yl_train, yl_test = train_test_split(Xl, yl, test_size=0.2,  random_state=1)\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nXl_train_std = scaler.fit_transform(Xl_train) \nXl_test_std = scaler.transform(Xl_test) ","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Split the data into 70% train and 30% test\nXl_train, Xl_test, yl_train, yl_test = train_test_split(Xl, yl, test_size=0.2,  random_state=1)\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nXl_train_std = scaler.fit_transform(Xl_train) \nXl_test_std = scaler.transform(Xl_test) "},"cell_type":"code","id":"371fbc11-092c-40e3-bbef-9933569a12d2","execution_count":350,"outputs":[]},{"source":"# Import models, including VotingClassifier meta-model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier as KNN\nfrom sklearn.ensemble import VotingClassifier\n# Instantiate lr\nlr = LogisticRegression(random_state=1)\n\n# Instantiate knn\nknn =KNN(n_neighbors=27)\n\n# Instantiate dt\ndt = DecisionTreeClassifier(min_samples_leaf=0.13, random_state=1)\n\n# Define the list classifiers\nclassifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn), ('Classification Tree', dt)]","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Import models, including VotingClassifier meta-model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier as KNN\nfrom sklearn.ensemble import VotingClassifier\n# Instantiate lr\nlr = LogisticRegression(random_state=1)\n\n# Instantiate knn\nknn =KNN(n_neighbors=27)\n\n# Instantiate dt\ndt = DecisionTreeClassifier(min_samples_leaf=0.13, random_state=1)\n\n# Define the list classifiers\nclassifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn), ('Classification Tree', dt)]"},"cell_type":"code","id":"331a3cb8-8b10-4c90-bb3c-1bf7bc67855c","execution_count":351,"outputs":[]},{"source":"**Evaluate individual classifiers**\n\nWe'll evaluate the performance of the models in the list classifiers that we defined ","metadata":{},"cell_type":"markdown","id":"c3396b94-dbfc-44aa-93e6-1730680e64c0"},{"source":"# Iterate over the pre-defined list of classifiers\nfor clf_name, clf in classifiers:    \n \n    # Fit clf to the training set\n    clf.fit(Xl_train_std, yl_train)    \n   \n    # Predict y_pred\n    yl_pred = clf.predict(Xl_test_std)\n    \n    # Calculate accuracy\n    accuracy = accuracy_score(yl_test, yl_pred) \n   \n    # Evaluate clf's accuracy on the test set\n    print('{:s} : {:.3f}'.format(clf_name, accuracy))","metadata":{"executionTime":32,"lastSuccessfullyExecutedCode":"# Iterate over the pre-defined list of classifiers\nfor clf_name, clf in classifiers:    \n \n    # Fit clf to the training set\n    clf.fit(Xl_train_std, yl_train)    \n   \n    # Predict y_pred\n    yl_pred = clf.predict(Xl_test_std)\n    \n    # Calculate accuracy\n    accuracy = accuracy_score(yl_test, yl_pred) \n   \n    # Evaluate clf's accuracy on the test set\n    print('{:s} : {:.3f}'.format(clf_name, accuracy))"},"cell_type":"code","id":"4ce6a1f5-42d9-4e15-a1f4-8c7757d2c247","execution_count":352,"outputs":[{"output_type":"stream","name":"stdout","text":"Logistic Regression : 0.767\nK Nearest Neighbours : 0.672\nClassification Tree : 0.707\n"}]},{"source":"**Better performance with a Voting Classifier**\n\nFinally, we'll evaluate the performance of a voting classifier that takes the outputs of the models defined in the list classifiers and assigns labels by majority voting.","metadata":{},"cell_type":"markdown","id":"7aeb70a3-e7cf-4845-8625-9e02e5fd23e5"},{"source":"# Import VotingClassifier from sklearn.ensemble\nfrom sklearn.ensemble import VotingClassifier\n\n# Instantiate a VotingClassifier vc\nvc = VotingClassifier(estimators=classifiers)     \n\n# Fit vc to the training set\nvc.fit(Xl_train_std, yl_train)   \n\n# Evaluate the test set predictions\ny_vc_pred = vc.predict(Xl_test_std)\n\n# Calculate accuracy score\naccuracy = accuracy_score(yl_test, y_vc_pred)\nprint('Voting Classifier: {:.3f}'.format(accuracy))","metadata":{"executionTime":40,"lastSuccessfullyExecutedCode":"# Import VotingClassifier from sklearn.ensemble\nfrom sklearn.ensemble import VotingClassifier\n\n# Instantiate a VotingClassifier vc\nvc = VotingClassifier(estimators=classifiers)     \n\n# Fit vc to the training set\nvc.fit(Xl_train_std, yl_train)   \n\n# Evaluate the test set predictions\ny_vc_pred = vc.predict(Xl_test_std)\n\n# Calculate accuracy score\naccuracy = accuracy_score(yl_test, y_vc_pred)\nprint('Voting Classifier: {:.3f}'.format(accuracy))"},"cell_type":"code","id":"a15442ed-7b39-4331-a562-02b83d4f3455","execution_count":353,"outputs":[{"output_type":"stream","name":"stdout","text":"Voting Classifier: 0.750\n"}]},{"source":"**Bagging classifier**\n\nWe'll work with the Indian Liver Patient dataset from the UCI machine learning repositoryand we will predict whether a patient suffers from a liver disease using a Bagging Classifier.","metadata":{},"cell_type":"markdown","id":"016c67f6-c08a-4b43-80b0-11ec18cccb22"},{"source":"# Import DecisionTreeClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Import BaggingClassifier\nfrom sklearn.ensemble import BaggingClassifier\n\n# Instantiate dt\ndt =DecisionTreeClassifier(random_state=1)\n\n# Instantiate bc\nbc = BaggingClassifier(base_estimator=dt, n_estimators=50, random_state=1)","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Import DecisionTreeClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Import BaggingClassifier\nfrom sklearn.ensemble import BaggingClassifier\n\n# Instantiate dt\ndt =DecisionTreeClassifier(random_state=1)\n\n# Instantiate bc\nbc = BaggingClassifier(base_estimator=dt, n_estimators=50, random_state=1)"},"cell_type":"code","id":"da455e7e-5a0c-49a2-ba5b-6b7e23d9ad6d","execution_count":354,"outputs":[]},{"source":"**Evaluate Bagging performance**","metadata":{},"cell_type":"markdown","id":"890cd86d-8eee-47cf-b190-7f0a92cd8a46"},{"source":"# Fit bc to the training set\nbc.fit(Xl_train_std, yl_train)\n\n# Predict test set labels\ny_bag_pred = bc.predict(Xl_test_std)\n\n# Evaluate acc_test\nacc_test = accuracy_score(yl_test, y_bag_pred)\nprint('Test set accuracy of bc: {:.2f}'.format(acc_test))","metadata":{"executionTime":41,"lastSuccessfullyExecutedCode":"# Fit bc to the training set\nbc.fit(Xl_train_std, yl_train)\n\n# Predict test set labels\ny_bag_pred = bc.predict(Xl_test_std)\n\n# Evaluate acc_test\nacc_test = accuracy_score(yl_test, y_bag_pred)\nprint('Test set accuracy of bc: {:.2f}'.format(acc_test))"},"cell_type":"code","id":"fb3733c0-ff88-462f-921d-d8e5e4551d44","execution_count":355,"outputs":[{"output_type":"stream","name":"stdout","text":"Test set accuracy of bc: 0.72\n"}]},{"source":"**Out Of Bag Evaluation**\n\nWe'll compare the OOB accuracy to the test set accuracy of a bagging classifier trained on the Indian Liver Patient dataset.\n\nIn sklearn, **we can evaluate the OOB accuracy of an ensemble classifier by setting the parameter oob_score to True** during instantiation. After training the classifier, the **OOB accuracy can be obtained by accessing the .oob_score_ attribute** from the corresponding instance.","metadata":{},"cell_type":"markdown","id":"34558b85-e402-4caf-87f1-259bdf516b00"},{"source":"# Import DecisionTreeClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Import BaggingClassifier\nfrom sklearn.ensemble import BaggingClassifier\n# Instantiate dt\ndt = DecisionTreeClassifier(min_samples_leaf=8, random_state=1)\n\n# Instantiate bc\nbc = BaggingClassifier(base_estimator=dt, \n            n_estimators=50,\n            oob_score=True,\n            random_state=1)","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Import DecisionTreeClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Import BaggingClassifier\nfrom sklearn.ensemble import BaggingClassifier\n# Instantiate dt\ndt = DecisionTreeClassifier(min_samples_leaf=8, random_state=1)\n\n# Instantiate bc\nbc = BaggingClassifier(base_estimator=dt, \n            n_estimators=50,\n            oob_score=True,\n            random_state=1)"},"cell_type":"code","id":"ff35292f-e1db-4e55-a9db-37f46ed3189f","execution_count":356,"outputs":[]},{"source":"# Fit bc to the training set \nbc.fit(Xl_train_std, yl_train)\n\n# Predict test set labels\ny_ood_pred = bc.predict(Xl_test_std)\n\n# Evaluate test set accuracy\nacc_test = accuracy_score(yl_test, y_ood_pred)\n\n# Evaluate OOB accuracy\nacc_oob = bc.oob_score_\n\n# Print acc_test and acc_oob\nprint('Test set accuracy: {:.3f}, OOB accuracy: {:.3f}'.format(acc_test, acc_oob))","metadata":{"executionTime":27,"lastSuccessfullyExecutedCode":"# Fit bc to the training set \nbc.fit(Xl_train_std, yl_train)\n\n# Predict test set labels\ny_ood_pred = bc.predict(Xl_test_std)\n\n# Evaluate test set accuracy\nacc_test = accuracy_score(yl_test, y_ood_pred)\n\n# Evaluate OOB accuracy\nacc_oob = bc.oob_score_\n\n# Print acc_test and acc_oob\nprint('Test set accuracy: {:.3f}, OOB accuracy: {:.3f}'.format(acc_test, acc_oob))"},"cell_type":"code","id":"4e9eee07-9a48-46ad-a3c7-f542ffc25e04","execution_count":357,"outputs":[{"output_type":"stream","name":"stdout","text":"Test set accuracy: 0.698, OOB accuracy: 0.680\n"}]},{"source":"The test set accuracy and the OOB accuracy of bc are both roughly equal to 70%!","metadata":{},"cell_type":"markdown","id":"90a2f688-c08b-42cd-b139-88c882b06f77"},{"source":"**Random Forest regressor**\n\nWe'll predict bike rental demand in the Capital Bikeshare program in Washington, D.C using historical weather data from the Bike Sharing Demand dataset available through Kaggle. For this purpose, we will be using the random forests algorithm.","metadata":{},"cell_type":"markdown","id":"551f50c5-3b90-4b48-80d7-ea7d68de6590"},{"source":"bikes_df= pd.read_csv('bikes.csv')\nbikes_df.head()","metadata":{"executionTime":48,"lastSuccessfullyExecutedCode":"bikes_df= pd.read_csv('bikes.csv')\nbikes_df.head()"},"cell_type":"code","id":"3f02663a-05a1-45ec-932c-9237a5fe59ab","execution_count":358,"outputs":[{"output_type":"execute_result","execution_count":358,"data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"hr","type":"integer"},{"name":"holiday","type":"integer"},{"name":"workingday","type":"integer"},{"name":"temp","type":"number"},{"name":"hum","type":"number"},{"name":"windspeed","type":"number"},{"name":"cnt","type":"integer"},{"name":"instant","type":"integer"},{"name":"mnth","type":"integer"},{"name":"yr","type":"integer"},{"name":"Clear to partly cloudy","type":"integer"},{"name":"Light Precipitation","type":"integer"},{"name":"Misty","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":0,"hr":0,"holiday":0,"workingday":0,"temp":0.76,"hum":0.66,"windspeed":0,"cnt":149,"instant":13004,"mnth":7,"yr":1,"Clear to partly cloudy":1,"Light Precipitation":0,"Misty":0},{"index":1,"hr":1,"holiday":0,"workingday":0,"temp":0.74,"hum":0.7,"windspeed":0.1343,"cnt":93,"instant":13005,"mnth":7,"yr":1,"Clear to partly cloudy":1,"Light Precipitation":0,"Misty":0},{"index":2,"hr":2,"holiday":0,"workingday":0,"temp":0.72,"hum":0.74,"windspeed":0.0896,"cnt":90,"instant":13006,"mnth":7,"yr":1,"Clear to partly cloudy":1,"Light Precipitation":0,"Misty":0},{"index":3,"hr":3,"holiday":0,"workingday":0,"temp":0.72,"hum":0.84,"windspeed":0.1343,"cnt":33,"instant":13007,"mnth":7,"yr":1,"Clear to partly cloudy":1,"Light Precipitation":0,"Misty":0},{"index":4,"hr":4,"holiday":0,"workingday":0,"temp":0.7,"hum":0.79,"windspeed":0.194,"cnt":4,"instant":13008,"mnth":7,"yr":1,"Clear to partly cloudy":1,"Light Precipitation":0,"Misty":0}]},"total_rows":5,"truncation_type":null},"text/plain":"   hr  holiday  workingday  ...  Clear to partly cloudy  Light Precipitation  Misty\n0   0        0           0  ...                       1                    0      0\n1   1        0           0  ...                       1                    0      0\n2   2        0           0  ...                       1                    0      0\n3   3        0           0  ...                       1                    0      0\n4   4        0           0  ...                       1                    0      0\n\n[5 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hr</th>\n      <th>holiday</th>\n      <th>workingday</th>\n      <th>temp</th>\n      <th>hum</th>\n      <th>windspeed</th>\n      <th>cnt</th>\n      <th>instant</th>\n      <th>mnth</th>\n      <th>yr</th>\n      <th>Clear to partly cloudy</th>\n      <th>Light Precipitation</th>\n      <th>Misty</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.76</td>\n      <td>0.66</td>\n      <td>0.0000</td>\n      <td>149</td>\n      <td>13004</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.74</td>\n      <td>0.70</td>\n      <td>0.1343</td>\n      <td>93</td>\n      <td>13005</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.72</td>\n      <td>0.74</td>\n      <td>0.0896</td>\n      <td>90</td>\n      <td>13006</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.72</td>\n      <td>0.84</td>\n      <td>0.1343</td>\n      <td>33</td>\n      <td>13007</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.70</td>\n      <td>0.79</td>\n      <td>0.1940</td>\n      <td>4</td>\n      <td>13008</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"Xb =bikes_df.drop('cnt', axis =1)\nyb = bikes_df['cnt']\nXb_train, Xb_test, yb_train, yb_test = train_test_split(Xb, yb, test_size=0.3, random_state=1)","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"Xb =bikes_df.drop('cnt', axis =1)\nyb = bikes_df['cnt']\nXb_train, Xb_test, yb_train, yb_test = train_test_split(Xb, yb, test_size=0.3, random_state=1)"},"cell_type":"code","id":"c8d76431-2073-4acd-966b-2b9567212077","execution_count":359,"outputs":[]},{"source":"# Import RandomForestRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Instantiate rf\nrfb = RandomForestRegressor(n_estimators=25,\n            random_state=2)\n            \n# Fit rf to the training set    \nrfb.fit(Xb_train, yb_train) ","metadata":{"executionTime":30,"lastSuccessfullyExecutedCode":"# Import RandomForestRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Instantiate rf\nrfb = RandomForestRegressor(n_estimators=25,\n            random_state=2)\n            \n# Fit rf to the training set    \nrfb.fit(Xb_train, yb_train) "},"cell_type":"code","id":"712a2092-abba-45d6-ba47-84b279bfa4f6","execution_count":360,"outputs":[{"output_type":"execute_result","execution_count":360,"data":{"text/plain":"RandomForestRegressor(n_estimators=25, random_state=2)","text/html":"<style>#sk-container-id-24 {color: black;background-color: white;}#sk-container-id-24 pre{padding: 0;}#sk-container-id-24 div.sk-toggleable {background-color: white;}#sk-container-id-24 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-24 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-24 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-24 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-24 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-24 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-24 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-24 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-24 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-24 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-24 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-24 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-24 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-24 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-24 div.sk-item {position: relative;z-index: 1;}#sk-container-id-24 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-24 div.sk-item::before, #sk-container-id-24 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-24 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-24 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-24 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-24 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-24 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-24 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-24 div.sk-label-container {text-align: center;}#sk-container-id-24 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-24 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-24\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=25, random_state=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" checked><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=25, random_state=2)</pre></div></div></div></div></div>"},"metadata":{}}]},{"source":"**Evaluate the RF regressor**","metadata":{},"cell_type":"markdown","id":"ca081da9-1173-4515-b0dd-41dcccc6166e"},{"source":"# Import mean_squared_error as MSE\nfrom sklearn.metrics import mean_squared_error as MSE\n\n# Predict the test set labels\nyb_pred = rfb.predict(Xb_test)\n\n# Evaluate the test set RMSE\nrmse_test = MSE(yb_test, yb_pred)**(1/2)\n# Print rmse_test\nprint('Test set RMSE of rf: {:.2f}'.format(rmse_test))","metadata":{"executionTime":30,"lastSuccessfullyExecutedCode":"# Import mean_squared_error as MSE\nfrom sklearn.metrics import mean_squared_error as MSE\n\n# Predict the test set labels\nyb_pred = rfb.predict(Xb_test)\n\n# Evaluate the test set RMSE\nrmse_test = MSE(yb_test, yb_pred)**(1/2)\n# Print rmse_test\nprint('Test set RMSE of rf: {:.2f}'.format(rmse_test))"},"cell_type":"code","id":"b4788da8-600a-438e-97e8-fd905b2e290c","execution_count":361,"outputs":[{"output_type":"stream","name":"stdout","text":"Test set RMSE of rf: 50.01\n"}]},{"source":"**Visualizing features importances**\n\nWe'll determine which features were the most predictive according to the random forests regressor.\n\nTree-based methods: enable measuring the importance of each feature in prediction, the feature importance **can be accessed using the attribute feature_importance_**. ","metadata":{},"cell_type":"markdown","id":"f7233181-5a6d-4556-81ae-cd5919a1ae14"},{"source":"# Create a pd.Series of features importances\nimportances = pd.Series(data=rfb.feature_importances_,\n                        index= Xb_train.columns)\n\n# Sort importances\nimportances_sorted = importances.sort_values()\n\n# Draw a horizontal barplot of importances_sorted\nimport matplotlib.pyplot as plt\nimportances_sorted.plot(kind='barh', color='lightgreen')\nplt.title('Features Importances')\nplt.show()","metadata":{"executionTime":83,"lastSuccessfullyExecutedCode":"# Create a pd.Series of features importances\nimportances = pd.Series(data=rfb.feature_importances_,\n                        index= Xb_train.columns)\n\n# Sort importances\nimportances_sorted = importances.sort_values()\n\n# Draw a horizontal barplot of importances_sorted\nimport matplotlib.pyplot as plt\nimportances_sorted.plot(kind='barh', color='lightgreen')\nplt.title('Features Importances')\nplt.show()"},"cell_type":"code","id":"8c1f3588-942d-4c1d-9eff-a8456c11832e","execution_count":362,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAqQAAAGzCAYAAAD5fQUXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAABS40lEQVR4nO3deVhV1f7H8c9hRoYDiAImigPO4kSaOVFZmmZqJtqg4tS95ngzK39l4pRmWtnkLSuwMr2VZmU5peJ1yCEVM/XikKQZZpaC6BUQ1u+PHs/thCgouEHfr+fZz8Pee+21v+uco3xce++jzRhjBAAAAFjExeoCAAAAcGMjkAIAAMBSBFIAAABYikAKAAAASxFIAQAAYCkCKQAAACxFIAUAAIClCKQAAACwFIEUAAAAliKQAgAAwFIEUgC4hMTERNlstosuTz31VImcc+PGjYqPj9epU6dKpP+SFhcXJ19fX6vLuGJnz55VfHy8kpKSrC4FuGG4WV0AAJQFEydOVLVq1Zy2NWjQoETOtXHjRk2YMEFxcXEKCAgokXOgYGfPntWECRMkSTExMdYWA9wgCKQAUAh33323oqOjrS7jqpw5c0Y+Pj5Wl1Fq5eXlKTs72+oygBsSl+wBoBgsXbpUbdq0kY+Pj/z8/NS5c2ft3r3bqc13332nuLg4Va9eXV5eXgoNDdWAAQP022+/OdrEx8drzJgxkqRq1ao5bg9ITU1VamqqbDabEhMT853fZrMpPj7eqR+bzaY9e/bowQcfVGBgoFq3bu3Y/8EHH6hZs2by9vZWUFCQevfurSNHjjj1uX//fvXo0UOhoaHy8vJS5cqV1bt3b6Wnpxf59YmIiNA999yjpKQkRUdHy9vbWw0bNnRcFl+0aJEaNmwoLy8vNWvWTDt27HA6/sJtAD/88IM6dOggHx8fVapUSRMnTpQxxqntmTNnNHr0aIWHh8vT01O1a9fWjBkz8rWz2WwaNmyY5s2bp/r168vT01P//Oc/VaFCBUnShAkTHK//hde2MO/hn1//AwcOOGa67Xa7+vfvr7Nnz+Z7fT744AM1b95c5cqVU2BgoNq2basVK1Y4tSnMZ+zYsWPq37+/KleuLE9PT4WFhalr165KTU0t1PsEWIUZUgAohPT0dJ04ccJpW3BwsCTp/fffV79+/dShQwc9//zzOnv2rGbPnq3WrVtrx44dioiIkCStXLlSP/zwg/r376/Q0FDt3r1bb731lnbv3q1NmzbJZrPpvvvu0759+zR//ny99NJLjnNUqFBBv/76a5Hr7tmzpyIjI/Xcc885AtmUKVM0btw4xcbGatCgQfr111/16quvqm3bttqxY4cCAgKUnZ2tDh06KCsrS8OHD1doaKiOHj2qJUuW6NSpU7Lb7UWu5cCBA3rwwQf1t7/9TQ8//LBmzJihLl266J///Kf+7//+T48++qgkaerUqYqNjVVKSopcXP43b5Kbm6uOHTvqlltu0fTp07Vs2TKNHz9e58+f18SJEyVJxhjde++9WrNmjQYOHKjGjRtr+fLlGjNmjI4ePaqXXnrJqabVq1fro48+0rBhwxQcHKxGjRpp9uzZGjJkiLp376777rtPkhQVFSWpcO/hn8XGxqpatWqaOnWqtm/frrffflsVK1bU888/72gzYcIExcfH69Zbb9XEiRPl4eGhzZs3a/Xq1brrrrskFf4z1qNHD+3evVvDhw9XRESEjh8/rpUrV+rw4cOONkCpZAAABUpISDCSLroYY8zp06dNQECAGTx4sNNxx44dM3a73Wn72bNn8/U/f/58I8n8+9//dmx74YUXjCRz6NAhp7aHDh0ykkxCQkK+fiSZ8ePHO9bHjx9vJJkHHnjAqV1qaqpxdXU1U6ZMcdq+a9cu4+bm5ti+Y8cOI8l8/PHHBb84BejXr5/x8fFx2la1alUjyWzcuNGxbfny5UaS8fb2Nj/++KNj+5tvvmkkmTVr1jj1KckMHz7csS0vL8907tzZeHh4mF9//dUYY8zixYuNJDN58mSn899///3GZrOZAwcOOLZJMi4uLmb37t1ObX/99dd8r+cFhX0PL7z+AwYMcGrbvXt3U758ecf6/v37jYuLi+nevbvJzc11apuXl2eMKfxn7OTJk0aSeeGFF/LVCJR2XLIHgEJ4/fXXtXLlSqdF+mPG7NSpU3rggQd04sQJx+Lq6qoWLVpozZo1jj68vb0dP587d04nTpzQLbfcIknavn17idT997//3Wl90aJFysvLU2xsrFO9oaGhioyMdNR7YQZ0+fLlF73EfCXq1aunli1bOtZbtGghSbr99ttVpUqVfNt/+OGHfH0MGzbM8fOFS+7Z2dn6+uuvJUlfffWVXF1dNWLECKfjRo8eLWOMli5d6rS9Xbt2qlevXqHHUNT38K+vf5s2bfTbb78pIyNDkrR48WLl5eXp2WefdZoNvjA+qfCfMW9vb3l4eCgpKUknT54s9JiA0oBL9gBQCM2bN7/oQ0379++X9Eeouhh/f3/Hz7///rsmTJigBQsW6Pjx407truS+zML46zcD7N+/X8YYRUZGXrS9u7u747jHHntML774oubNm6c2bdro3nvv1cMPP3xFl+slOYVO6X+hNzw8/KLb/xqqXFxcVL16dadttWrVkiTHPZI//vijKlWqJD8/P6d2devWdez/s7++PpdT1Pfwr2MODAyU9MfY/P39dfDgQbm4uFwyFBf2M+bp6annn39eo0ePVkhIiG655Rbdc8896tu3r0JDQws/SMACBFIAuAp5eXmS/rjH72K/9N3c/vfXbGxsrDZu3KgxY8aocePG8vX1VV5enjp27Ojo51L+en/iBbm5uQUe8+cZvQv12mw2LV26VK6urvna//n7Q2fOnKm4uDh99tlnWrFihUaMGKGpU6dq06ZNqly58mXr/auLne9S281fHkIqCX99fS6nqO9hcYytKJ+xUaNGqUuXLlq8eLGWL1+ucePGaerUqVq9erWaNGlS6HMC1xqBFACuQo0aNSRJFStWVPv27Qtsd/LkSa1atUoTJkzQs88+69h+YfbrzwoKnhdm1/76hfl/nfW7XL3GGFWrVs0xu3gpDRs2VMOGDfXMM89o48aNatWqlf75z39q8uTJhT5nccnLy9MPP/zgVPe+ffskyfHATtWqVfX111/r9OnTTrOk//nPfxz7L6eg178o72Fh1ahRQ3l5edqzZ48aN25cYBvp8p+xP7cfPXq0Ro8erf3796tx48aaOXOmPvjggyuuEyhp3EMKAFehQ4cO8vf313PPPaecnJx8+y88GX9hpuyvM2Mvv/xyvmMufFfoX4Onv7+/goOD9e9//9tp+xtvvFHoeu+77z65urpqwoQJ+Woxxji+vigjI0Pnz5932t+wYUO5uLgoKyur0Ocrbq+99prjZ2OMXnvtNbm7u+uOO+6QJHXq1Em5ublO7STppZdeks1m0913333Zc5QrV05S/te/KO9hYXXr1k0uLi6aOHFivhnWC+cp7Gfs7NmzOnfunNO+GjVqyM/Pz9L3DCgMZkgB4Cr4+/tr9uzZ6tOnj5o2barevXurQoUKOnz4sL788ku1atVKr732mvz9/dW2bVtNnz5dOTk5uummm7RixQodOnQoX5/NmjWTJD399NPq3bu33N3d1aVLF/n4+GjQoEGaNm2aBg0apOjoaP373/92zBIWRo0aNTR58mSNHTtWqamp6tatm/z8/HTo0CF9+umneuSRR/T4449r9erVGjZsmHr27KlatWrp/Pnzev/99+Xq6qoePXoU2+tXFF5eXlq2bJn69eunFi1aaOnSpfryyy/1f//3f47vDu3SpYtuu+02Pf3000pNTVWjRo20YsUKffbZZxo1apRjtvFSvL29Va9ePf3rX/9SrVq1FBQUpAYNGqhBgwaFfg8Lq2bNmnr66ac1adIktWnTRvfdd588PT21detWVapUSVOnTi30Z2zfvn264447FBsbq3r16snNzU2ffvqpfvnlF/Xu3fuKawSuCYue7geAMuHC1z5t3br1ku3WrFljOnToYOx2u/Hy8jI1atQwcXFx5ttvv3W0+emnn0z37t1NQECAsdvtpmfPnubnn3++6FcMTZo0ydx0003GxcXF6Sugzp49awYOHGjsdrvx8/MzsbGx5vjx4wV+7dOFr0P6q4ULF5rWrVsbHx8f4+PjY+rUqWOGDh1qUlJSjDHG/PDDD2bAgAGmRo0axsvLywQFBZnbbrvNfP3115d9zQr62qfOnTvnayvJDB061Gnbha+3+vPXF13o8+DBg+auu+4y5cqVMyEhIWb8+PH5vi7p9OnT5h//+IepVKmScXd3N5GRkeaFF15wfI3Spc59wcaNG02zZs2Mh4eH02tb2PewoNf/wufpr1/p9e6775omTZoYT09PExgYaNq1a2dWrlzp1OZyn7ETJ06YoUOHmjp16hgfHx9jt9tNixYtzEcffXTRMQKlic2Ya3DXOAAAVyEuLk6ffPKJMjMzrS4FQAngHlIAAABYikAKAAAASxFIAQAAYCnuIQUAAIClmCEFAACApQikAAAAsBRfjI9SLy8vTz///LP8/PwK/C/9AABA6WKM0enTp1WpUiW5uFx6DpRAilLv559/Vnh4uNVlAACAK3DkyBFVrlz5km0IpCj1/Pz8JP3xgfb397e4GgAAUBgZGRkKDw93/B6/FAIpSr0Ll+n9/f0JpAAAlDGFud2Oh5oAAABgKQIpAAAALEUgBQAAgKUIpAAAALAUDzWhzJh9cra8cr2sLgMAgOvGyMCRVpcgiRlSAAAAWIxACgAAAEsRSFFsYmJiNGrUKKvLAAAAZQyBFAAAAJYikMIyOTk5VpcAAABKAQIpilVeXp6eeOIJBQUFKTQ0VPHx8Y59NptNs2fP1r333isfHx9NmTLFukIBAECpQSBFsZo7d658fHy0efNmTZ8+XRMnTtTKlSsd++Pj49W9e3ft2rVLAwYMuGgfWVlZysjIcFoAAMD1i0CKYhUVFaXx48crMjJSffv2VXR0tFatWuXY/+CDD6p///6qXr26qlSpctE+pk6dKrvd7ljCw8OvVfkAAMACBFIUq6ioKKf1sLAwHT9+3LEeHR192T7Gjh2r9PR0x3LkyJFirxMAAJQe/E9NKFbu7u5O6zabTXl5eY51Hx+fy/bh6ekpT0/PYq8NAACUTsyQAgAAwFIEUgAAAFiKQAoAAABLcQ8pik1SUlK+bYsXL3b8bIy5dsUAAIAygxlSAAAAWIoZUpQZQwKHyN/f3+oyAABAMWOGFAAAAJYikAIAAMBSBFIAAABYikAKAAAASxFIAQAAYCkCKQAAACxFIAUAAIClCKQAAACwFIEUAAAAliKQAgAAwFIEUgAAAFiKQAoAAABLEUgBAABgKQIpAAAALOVmdQFAYc0+OVteuV5Wl3FDGRk40uoSAAA3AGZIAQAAYCkCKQAAACxFIC0DUlNTZbPZlJycXGAbm82mxYsXl3gt8fHxaty4cYmfBwAA3Di4h/Q6kZaWpsDAQKvLAAAAKDICaSmXnZ1dqHahoaElXAkAAEDJ4JL9VVqyZIkCAgKUm5srSUpOTpbNZtNTTz3laDNo0CA9/PDDkqSFCxeqfv368vT0VEREhGbOnOnUX0REhCZNmqS+ffvK399fjzzySL5z5ubmasCAAapTp44OHz4syfmS/YVL/IsWLdJtt92mcuXKqVGjRvrmm2+c+pkzZ47Cw8NVrlw5de/eXS+++KICAgKc2kybNk0hISHy8/PTwIEDde7cOaf9W7du1Z133qng4GDZ7Xa1a9dO27dvd+wfMGCA7rnnHqdjcnJyVLFiRb3zzjuXe3kBAMANgEB6ldq0aaPTp09rx44dkqS1a9cqODhYSUlJjjZr165VTEyMtm3bptjYWPXu3Vu7du1SfHy8xo0bp8TERKc+Z8yYoUaNGmnHjh0aN26c076srCz17NlTycnJWrdunapUqVJgbU8//bQef/xxJScnq1atWnrggQd0/vx5SdKGDRv097//XSNHjlRycrLuvPNOTZkyxen4jz76SPHx8Xruuef07bffKiwsTG+88YZTm9OnT6tfv35av369Nm3apMjISHXq1EmnT5+W9EcYX7ZsmdLS0hzHLFmyRGfPnlWvXr0uWndWVpYyMjKcFgAAcP2yGWOM1UWUdc2aNdMDDzygxx9/XN27d9fNN9+sCRMm6LffflN6eroqV66sffv2KT4+Xr/++qtWrFjhOPaJJ57Ql19+qd27d0v6Y4a0SZMm+vTTTx1tUlNTVa1aNa1bt07x8fHKysrSkiVLZLfbHW1sNps+/fRTdevWzdH+7bff1sCBAyVJe/bsUf369bV3717VqVNHvXv3VmZmppYsWeLo4+GHH9aSJUt06tQpSdKtt96qJk2a6PXXX3e0ueWWW3Tu3LkCH7DKy8tTQECAPvzwQ8fMaP369dWvXz898cQTkqR7771X5cuXV0JCwkX7iI+P14QJE/Jtn5Y6TV7+fA/ptcT3kAIArlRGRobsdrvS09Pl7+9/ybbMkBaDdu3aKSkpScYYrVu3Tvfdd5/q1q2r9evXa+3atapUqZIiIyO1d+9etWrVyunYVq1aaf/+/Y5L/pIUHR190fM88MADOnPmjFasWOEURgsSFRXl+DksLEySdPz4cUlSSkqKmjdv7tT+r+t79+5VixYtnLa1bNnSaf2XX37R4MGDFRkZKbvdLn9/f2VmZjpuJZD+mCW9ED5/+eUXLV26VAMGDCiw7rFjxyo9Pd2xHDly5LJjBQAAZReBtBjExMRo/fr12rlzp9zd3VWnTh3FxMQoKSlJa9euVbt27YrUn4+Pz0W3d+rUSd99912+e0EL4u7u7vjZZrNJ+mMGszj169dPycnJmjVrljZu3Kjk5GSVL1/e6WGsvn376ocfftA333yjDz74QNWqVVObNm0K7NPT01P+/v5OCwAAuH4RSIvBhftIX3rpJUf4vBBIk5KSFBMTI0mqW7euNmzY4HTshg0bVKtWLbm6ul72PEOGDNG0adN07733au3atVdVc+3atbV161anbX9dr1u3rjZv3uy0bdOmTU7rGzZs0IgRI9SpUyfHw1onTpxwalO+fHl169ZNCQkJSkxMVP/+/a+qdgAAcH3ha5+KQWBgoKKiojRv3jy99tprkqS2bdsqNjZWOTk5jpA6evRo3XzzzZo0aZJ69eqlb775Rq+99lq+B4UuZfjw4crNzdU999yjpUuXqnXr1ldU8/Dhw9W2bVu9+OKL6tKli1avXq2lS5c6ZlIlaeTIkYqLi1N0dLRatWqlefPmaffu3apevbqjTWRkpN5//31FR0crIyNDY8aMkbe3d77zDRo0SPfcc49yc3PVr1+/K6oZAABcn5ghLSbt2rVTbm6uYzY0KChI9erVU2hoqGrXri1Jatq0qT766CMtWLBADRo00LPPPquJEycqLi6uSOcaNWqUJkyYoE6dOmnjxo1XVG+rVq30z3/+Uy+++KIaNWqkZcuW6R//+Ie8vP730FCvXr00btw4PfHEE2rWrJl+/PFHDRkyxKmfd955RydPnlTTpk3Vp08fjRgxQhUrVsx3vvbt2yssLEwdOnRQpUqVrqhmAABwfeIpezgMHjxY//nPf7Ru3bpi7zszM1M33XSTEhISdN999xXp2AtP6fGU/bXHU/YAgCtVlKfsuWR/A5sxY4buvPNO+fj4aOnSpZo7d26Rbh8ojLy8PJ04cUIzZ85UQECA7r333mLtHwAAlH0E0hvYli1bNH36dJ0+fVrVq1fXK6+8okGDBhXrOQ4fPqxq1aqpcuXKSkxMlJvblX/khgQO4Yl7AACuQ1yyR6lXlCl/AABQOvDF+AAAACgzCKQAAACwFIEUAAAAliKQAgAAwFIEUgAAAFiKQAoAAABLEUgBAABgKQIpAAAALEUgBQAAgKUIpAAAALAUgRQAAACWIpACAADAUgRSAAAAWMrN6gKAwpp9cra8cr2u6NiRgSOLuRoAAFBcmCEFAACApQikAAAAsBSBFA4xMTEaNWqU1WUAAIAbDIEUAAAAliKQAgAAwFIEUjjJy8vTE088oaCgIIWGhio+Pl6SlJqaKpvNpuTkZEfbU6dOyWazKSkpSZKUlJQkm82m5cuXq0mTJvL29tbtt9+u48ePa+nSpapbt678/f314IMP6uzZs9d+cAAAoFTia5/gZO7cuXrssce0efNmffPNN4qLi1OrVq0UGRlZ6D7i4+P12muvqVy5coqNjVVsbKw8PT314YcfKjMzU927d9err76qJ5988qLHZ2VlKSsry7GekZFx1eMCAAClFzOkcBIVFaXx48crMjJSffv2VXR0tFatWlWkPiZPnqxWrVqpSZMmGjhwoNauXavZs2erSZMmatOmje6//36tWbOmwOOnTp0qu93uWMLDw692WAAAoBQjkMJJVFSU03pYWJiOHz9+xX2EhISoXLlyql69utO2S/U5duxYpaenO5YjR44U6fwAAKBs4ZI9nLi7uzut22w25eXlycXlj3+7GGMc+3Jyci7bh81mK7DPgnh6esrT07PItQMAgLKJGVIUSoUKFSRJaWlpjm1/fsAJAADgSjFDikLx9vbWLbfcomnTpqlatWo6fvy4nnnmGavLAgAA1wFmSFFo7777rs6fP69mzZpp1KhRmjx5stUlAQCA64DN/PmmQKAUysjIkN1u17TUafLy97qiPkYGjizmqgAAwKVc+P2dnp4uf3//S7blkj3KjCGBQy77gQYAAGUPl+wBAABgKQIpAAAALEUgBQAAgKUIpAAAALAUgRQAAACWIpACAADAUgRSAAAAWIpACgAAAEsRSAEAAGApAikAAAAsRSAFAACApQikAAAAsBSBFAAAAJYikAIAAMBSBFIAAABYys3qAoDCmn1ytrxyvQrdfmTgyBKsBgAAFBdmSAEAAGApAikAAAAsRSAFAACApQikN6CYmBiNGjXK6jIAAAAkEUgBAABgMQLpDSYuLk5r167VrFmzZLPZZLPZlJqaqu+//1533323fH19FRISoj59+ujEiROO42JiYjR8+HCNGjVKgYGBCgkJ0Zw5c3TmzBn1799ffn5+qlmzppYuXeo4JikpSTabTV9++aWioqLk5eWlW265Rd9///0la8zKylJGRobTAgAArl8E0hvMrFmz1LJlSw0ePFhpaWlKS0uTn5+fbr/9djVp0kTffvutli1bpl9++UWxsbFOx86dO1fBwcHasmWLhg8friFDhqhnz5669dZbtX37dt11113q06ePzp4963TcmDFjNHPmTG3dulUVKlRQly5dlJOTU2CNU6dOld1udyzh4eEl8loAAIDSwWaMMVYXgWsrJiZGjRs31ssvvyxJmjx5statW6fly5c72vz0008KDw9XSkqKatWqpZiYGOXm5mrdunWSpNzcXNntdt1333167733JEnHjh1TWFiYvvnmG91yyy1KSkrSbbfdpgULFqhXr16SpN9//12VK1dWYmJivsB7QVZWlrKyshzrGRkZCg8P17TUafLy53tIAQAoCzIyMmS325Weni5/f/9LtuWL8aGdO3dqzZo18vX1zbfv4MGDqlWrliQpKirKsd3V1VXly5dXw4YNHdtCQkIkScePH3fqo2XLlo6fg4KCVLt2be3du7fAejw9PeXp6XllgwEAAGUOgRTKzMxUly5d9Pzzz+fbFxYW5vjZ3d3daZ/NZnPaZrPZJEl5eXklVCkAALgeEUhvQB4eHsrNzXWsN23aVAsXLlRERITc3Ir/I7Fp0yZVqVJFknTy5Ent27dPdevWLfbzAACAsomHmm5AERER2rx5s1JTU3XixAkNHTpUv//+ux544AFt3bpVBw8e1PLly9W/f3+n4HqlJk6cqFWrVun7779XXFycgoOD1a1bt6sfCAAAuC4QSG9Ajz/+uFxdXVWvXj1VqFBB2dnZ2rBhg3Jzc3XXXXepYcOGGjVqlAICAuTicvUfkWnTpmnkyJFq1qyZjh07pi+++EIeHh7FMBIAAHA94JL9DahWrVr65ptv8m1ftGhRgcckJSXl25aamppv28W+tKF169aX/e5RAABw4yKQoswYEjjksl8bAQAAyh4u2QMAAMBSzJCixMTExFz0Ej4AAMCfMUMKAAAASxFIAQAAYCkCKQAAACxFIAUAAIClCKQAAACwFIEUAAAAliKQAgAAwFIEUgAAAFiKQAoAAABLEUgBAABgKQIpAAAALEUgBQAAgKUIpAAAALCUm9UFAIU1++RseeV6Fbr9yMCRJVgNAAAoLsyQAgAAwFIE0utETEyMRo0aZXUZAAAARUYgvU4sWrRIkyZNKpa+bDabFi9eXCx9/VlqaqpsNpuSk5OLvW8AAFB2cQ/pdSIoKMjqEgAAAK4IM6TXiT9fso+IiNBzzz2nAQMGyM/PT1WqVNFbb73laJudna1hw4YpLCxMXl5eqlq1qqZOneo4VpK6d+8um83mWD948KC6du2qkJAQ+fr66uabb9bXX3/tVMPlzlutWjVJUpMmTWSz2RQTE1MyLwYAAChTCKTXqZkzZyo6Olo7duzQo48+qiFDhiglJUWS9Morr+jzzz/XRx99pJSUFM2bN88RPLdu3SpJSkhIUFpammM9MzNTnTp10qpVq7Rjxw517NhRXbp00eHDhwt93i1btkiSvv76a6WlpWnRokUXrT0rK0sZGRlOCwAAuH4RSK9TnTp10qOPPqqaNWvqySefVHBwsNasWSNJOnz4sCIjI9W6dWtVrVpVrVu31gMPPCBJqlChgiQpICBAoaGhjvVGjRrpb3/7mxo0aKDIyEhNmjRJNWrU0Oeff17o817oq3z58goNDS3wNoOpU6fKbrc7lvDw8OJ/gQAAQKlBIL1ORUVFOX622WwKDQ3V8ePHJUlxcXFKTk5W7dq1NWLECK1YseKy/WVmZurxxx9X3bp1FRAQIF9fX+3duzffDOmlzltYY8eOVXp6umM5cuRIkY4HAABlCw81Xafc3d2d1m02m/Ly8iRJTZs21aFDh7R06VJ9/fXXio2NVfv27fXJJ58U2N/jjz+ulStXasaMGapZs6a8vb11//33Kzs7u9DnLSxPT095enoW6RgAAFB2EUhvUP7+/urVq5d69eql+++/Xx07dtTvv/+uoKAgubu7Kzc316n9hg0bFBcXp+7du0v6Y8Y0NTW1SOf08PCQpHx9AwCAGxuB9Ab04osvKiwsTE2aNJGLi4s+/vhjhYaGKiAgQNIfT8uvWrVKrVq1kqenpwIDAxUZGalFixapS5custlsGjduXJFnPitWrChvb28tW7ZMlStXlpeXl+x2ewmMEAAAlCXcQ3oD8vPz0/Tp0xUdHa2bb75Zqamp+uqrr+Ti8sfHYebMmVq5cqXCw8PVpEkTSX+E2MDAQN16663q0qWLOnTooKZNmxbpvG5ubnrllVf05ptvqlKlSuratWuxjw0AAJQ9NmOMsboI4FIyMjJkt9s1LXWavPy9Cn3cyMCRJVgVAAC4lAu/v9PT0+Xv73/JtsyQAgAAwFLcQ4oyY0jgkMv+CwsAAJQ9zJACAADAUgRSAAAAWIpACgAAAEsRSAEAAGApAikAAAAsRSAFAACApQikAAAAsBSBFAAAAJYikAIAAMBSBFIAAABYikAKAAAASxFIAQAAYCkCKQAAACxFIAUAAICl3KwuACis2SdnyyvXy7E+MnCkhdUAAIDiwgwpAAAALEUgBQAAgKUIpKVAYmKiAgICrrqfmJgYjRo16qr7KWkRERF6+eWXrS4DAACUEgTSUqBXr17at2+f1WUAAABYgoeaSgFvb295e3tbXQYAAIAlmCEtIUuWLFFAQIByc3MlScnJybLZbHrqqaccbQYNGqSHH3443yX7+Ph4NW7cWO+//74iIiJkt9vVu3dvnT592tHmzJkz6tu3r3x9fRUWFqaZM2fmq+GNN95QZGSkvLy8FBISovvvv9+xLyYmRsOGDdOwYcNkt9sVHByscePGyRjjaJOVlaXHH39cN910k3x8fNSiRQslJSU5nWP9+vVq06aNvL29FR4erhEjRujMmTOO/cePH1eXLl3k7e2tatWqad68eVf8mgIAgOsTgbSEtGnTRqdPn9aOHTskSWvXrlVwcLBToFu7dq1iYmIuevzBgwe1ePFiLVmyREuWLNHatWs1bdo0x/4xY8Zo7dq1+uyzz7RixQolJSVp+/btjv3ffvutRowYoYkTJyolJUXLli1T27Ztnc4xd+5cubm5acuWLZo1a5ZefPFFvf322479w4YN0zfffKMFCxbou+++U8+ePdWxY0ft37/fUWPHjh3Vo0cPfffdd/rXv/6l9evXa9iwYY4+4uLidOTIEa1Zs0affPKJ3njjDR0/fvySr11WVpYyMjKcFgAAcB0zKDFNmzY1L7zwgjHGmG7dupkpU6YYDw8Pc/r0afPTTz8ZSWbfvn0mISHB2O12x3Hjx4835cqVMxkZGY5tY8aMMS1atDDGGHP69Gnj4eFhPvroI8f+3377zXh7e5uRI0caY4xZuHCh8ff3d+rjz9q1a2fq1q1r8vLyHNuefPJJU7duXWOMMT/++KNxdXU1R48edTrujjvuMGPHjjXGGDNw4EDzyCOPOO1ft26dcXFxMf/9739NSkqKkWS2bNni2L93714jybz00ksFvm7jx483kvIt01KnmZd/f9mxAACA0is9Pd1IMunp6ZdtywxpCWrXrp2SkpJkjNG6det03333qW7dulq/fr3Wrl2rSpUqKTIy8qLHRkREyM/Pz7EeFhbmmFk8ePCgsrOz1aJFC8f+oKAg1a5d27F+5513qmrVqqpevbr69OmjefPm6ezZs07nuOWWW2Sz2RzrLVu21P79+5Wbm6tdu3YpNzdXtWrVkq+vr2NZu3atDh48KEnauXOnEhMTnfZ36NBBeXl5OnTokPbu3Ss3Nzc1a9bMcY46depc9hsFxo4dq/T0dMdy5MiRy7zSAACgLOOhphIUExOjd999Vzt37pS7u7vq1KmjmJgYJSUl6eTJk2rXrl2Bx7q7uzut22w25eXlFfrcfn5+2r59u5KSkrRixQo9++yzio+P19atWwv1FVOZmZlydXXVtm3b5Orq6rTP19fX0eZvf/ubRowYke/4KlWqXPE3B3h6esrT0/OKjgUAAGUPM6Ql6MJ9pC+99JIjfF4IpElJSQXeP3o5NWrUkLu7uzZv3uzYdvLkyXwB0M3NTe3bt9f06dP13XffKTU1VatXr3bs//PxkrRp0yZFRkbK1dVVTZo0UW5uro4fP66aNWs6LaGhoZKkpk2bas+ePfn216xZUx4eHqpTp47Onz+vbdu2Oc6RkpKiU6dOXdG4AQDA9YlAWoICAwMVFRWlefPmOcJn27ZttX37du3bt++SM6SX4uvrq4EDB2rMmDFavXq1vv/+e8XFxcnF5X9v55IlS/TKK68oOTlZP/74o9577z3l5eU5XdY/fPiwHnvsMaWkpGj+/Pl69dVXNXLkH/8/fK1atfTQQw+pb9++WrRokQ4dOqQtW7Zo6tSp+vLLLyVJTz75pDZu3Khhw4YpOTlZ+/fv12effeZ4qKl27drq2LGj/va3v2nz5s3atm2bBg0axFdcAQAAJ1yyL2Ht2rVTcnKyI5AGBQWpXr16+uWXX5zCYVG98MILyszMVJcuXeTn56fRo0crPT3dsT8gIECLFi1SfHy8zp07p8jISM2fP1/169d3tOnbt6/++9//qnnz5nJ1ddXIkSP1yCOPOPYnJCRo8uTJGj16tI4eParg4GDdcsstuueeeyRJUVFRWrt2rZ5++mm1adNGxhjVqFFDvXr1cupj0KBBateunUJCQjR58mSNGzfuiscNAACuPzZj/vTFk7hhxMTEqHHjxmXiv/DMyMiQ3W7XtNRp8vL3cmwfGTjSwqoAAMClXPj9nZ6eLn9//0u25ZI9AAAALMUle5QZQwKHXPZfWAAAoOwhkN6g/vpfgAIAAFiFS/YAAACwFIEUAAAAliKQAgAAwFIEUgAAAFiKQAoAAABLEUgBAABgKQIpAAAALEUgBQAAgKUIpAAAALAUgRQAAACWIpACAADAUgRSAAAAWIpACgAAAEu5WV0AUFizT86WV66XJGlk4EiLqwEAAMWFGVIAAABYikAKAAAAS5WpQGqz2bR48eJCt09KSpLNZtOpU6dKrKaSFhERoZdffrnQ7VNTU2Wz2ZScnFwi9cTFxalbt24l0jcAALgxlapAermwk5aWprvvvrtYzxkfH6/GjRsXqp3NZpPNZpObm5siIiL0j3/8Q5mZmcVaz19t3bpVjzzySKHbh4eHKy0tTQ0aNJB05aG8oGA7a9YsJSYmFqkvAACASylTDzWFhoZaev769evr66+/1vnz57VhwwYNGDBAZ8+e1ZtvvpmvbXZ2tjw8PK76nBUqVChSe1dX1xJ9nex2e4n1DQAAbkylaob0cv56yX7jxo1q3LixvLy8FB0drcWLF190Vm/btm2Kjo5WuXLldOuttyolJUWSlJiYqAkTJmjnzp2O2c9Lzf65ubkpNDRUlStXVq9evfTQQw/p888/l/S/mda3335b1apVk5fXH0+Dnzp1SoMGDVKFChXk7++v22+/XTt37nTq94svvtDNN98sLy8vBQcHq3v37o59f71kb7PZNHv2bN19993y9vZW9erV9cknnzj2/3lmMzU1VbfddpskKTAwUDabTXFxcZKkZcuWqXXr1goICFD58uV1zz336ODBg45+qlWrJklq0qSJbDabYmJiJOWfxc7KytKIESNUsWJFeXl5qXXr1tq6datj/4UZ2lWrVl30PQAAAChTgfTPMjIy1KVLFzVs2FDbt2/XpEmT9OSTT1607dNPP62ZM2fq22+/lZubmwYMGCBJ6tWrl0aPHq369esrLS1NaWlp6tWrV6Fr8Pb2VnZ2tmP9wIEDWrhwoRYtWuQIxT179tTx48e1dOlSbdu2TU2bNtUdd9yh33//XZL05Zdfqnv37urUqZN27NihVatWqXnz5pc877hx49SjRw/t3LlTDz30kHr37q29e/fmaxceHq6FCxdKklJSUpSWlqZZs2ZJks6cOaPHHntM3377rVatWiUXFxd1795deXl5kqQtW7ZIkr7++mulpaVp0aJFF63liSee0MKFCzV37lxt375dNWvWVIcOHRzju6Cg9+BisrKylJGR4bQAAIDrV5m6ZP9nH374oWw2m+bMmSMvLy/Vq1dPR48e1eDBg/O1nTJlitq1aydJeuqpp9S5c2edO3dO3t7e8vX1dcx8FsW2bdv04Ycf6vbbb3dsy87O1nvvvee4zL5+/Xpt2bJFx48fl6enpyRpxowZWrx4sT755BM98sgjmjJlinr37q0JEyY4+mnUqNElz92zZ08NGjRIkjRp0iStXLlSr776qt544w2ndq6urgoKCpIkVaxYUQEBAY59PXr0cGr77rvvqkKFCtqzZ48aNGjgGEP58uULfG3OnDmj2bNnKzEx0XFv75w5c7Ry5Uq98847GjNmjKNtQe/BhZnkP5s6darT6wEAAK5vZXaGNCUlRVFRUU6BpqCZxaioKMfPYWFhkqTjx48X+Zy7du2Sr6+vvL291bx5c7Vs2VKvvfaaY3/VqlWd7vncuXOnMjMzVb58efn6+jqWQ4cOOS6PJycn64477ihSHS1btsy3frEZ0kvZv3+/HnjgAVWvXl3+/v6KiIiQJB0+fLjQfRw8eFA5OTlq1aqVY5u7u7uaN2+er56ivAdjx45Venq6Yzly5EihawIAAGVPmZ0hLQp3d3fHzzabTZIcl6aLonbt2vr888/l5uamSpUq5XtoycfHx2k9MzNTYWFhSkpKytfXhdlKb2/vItdRHLp06aKqVatqzpw5qlSpkvLy8tSgQQOnWxCKU1HeA09PT8eMMgAAuP6V2RnS2rVra9euXcrKynJs+/PDNIXl4eGh3NzcQretWbOmIiIiCvUEfdOmTXXs2DG5ubmpZs2aTktwcLCkP2YOV61aVaSaN23alG+9bt26BdYsyWmMv/32m1JSUvTMM8/ojjvuUN26dXXy5MnLHvdXNWrUkIeHhzZs2ODYlpOTo61bt6pevXpFGhMAALhxlboZ0vT09HxPyZcvX17h4eFO2x588EE9/fTTeuSRR/TUU0/p8OHDmjFjhqT/zcAVRkREhA4dOqTk5GRVrlxZfn5+xTY71759e7Vs2VLdunXT9OnTVatWLf3888+OB5mio6M1fvx43XHHHapRo4Z69+6t8+fP66uvvirwAS1J+vjjjxUdHa3WrVtr3rx52rJli955552Ltq1atapsNpuWLFmiTp06ydvbW4GBgSpfvrzeeusthYWF6fDhw3rqqaecjqtYsaK8vb21bNkyVa5cWV5eXvm+8snHx0dDhgzRmDFjFBQUpCpVqmj69Ok6e/asBg4cePUvIAAAuCGUuhnSpKQkNWnSxGm52AMu/v7++uKLL5ScnKzGjRvr6aef1rPPPitJF31QpiA9evRQx44dddttt6lChQqaP39+sY3FZrPpq6++Utu2bdW/f3/VqlVLvXv31o8//qiQkBBJUkxMjD7++GN9/vnnaty4sW6//XbHE+4FmTBhghYsWKCoqCi99957mj9/foEzkjfddJMmTJigp556SiEhIRo2bJhcXFy0YMECbdu2TQ0aNNA//vEPvfDCC07Hubm56ZVXXtGbb76pSpUqqWvXrhftf9q0aerRo4f69Omjpk2b6sCBA1q+fLkCAwOv4BUDAAA3IpsxxlhdRHGZN2+e+vfvr/T0dMvuzSxpNptNn3766Q3133dmZGTIbrdrWuo0efn/8Y+NkYEjLa4KAABcyoXf3+np6fL3979k21J3yb4o3nvvPVWvXl033XSTdu7cqSeffFKxsbHXbRgFAAC4HpXpQHrs2DE9++yzOnbsmMLCwtSzZ09NmTLF6rJQQoYEDrnsv7AAAEDZc11dssf1qShT/gAAoHQoyu/vUvdQEwAAAG4sBFIAAABYikAKAAAASxFIAQAAYCkCKQAAACxFIAUAAIClCKQAAACwFIEUAAAAliKQAgAAwFIEUgAAAFiKQAoAAABLEUgBAABgKQIpAAAALEUgRZkx++Rsq0sAAAAlgEAKAAAASxFIAQAAYCkCaRkWExOjUaNGXfHx8fHxaty4sWM9Li5O3bp1K9FzAgAA/JWb1QWg9Jg1a5aMMVaXAQAAbjAEUjjY7XarSwAAADcgLtmXcXl5eXriiScUFBSk0NBQxcfHO/YdPnxYXbt2la+vr/z9/RUbG6tffvmlwL7+esn+zJkz6tu3r3x9fRUWFqaZM2fmO+b9999XdHS0/Pz8FBoaqgcffFDHjx+XJBljVLNmTc2YMcPpmOTkZNlsNh04cODqBg8AAK4LBNIybu7cufLx8dHmzZs1ffp0TZw4UStXrlReXp66du2q33//XWvXrtXKlSv1ww8/qFevXoXue8yYMVq7dq0+++wzrVixQklJSdq+fbtTm5ycHE2aNEk7d+7U4sWLlZqaqri4OEmSzWbTgAEDlJCQ4HRMQkKC2rZtq5o1a170vFlZWcrIyHBaAADA9YtL9mVcVFSUxo8fL0mKjIzUa6+9plWrVkmSdu3apUOHDik8PFyS9N5776l+/fraunWrbr755kv2m5mZqXfeeUcffPCB7rjjDkl/hN/KlSs7tRswYIDj5+rVq+uVV17RzTffrMzMTPn6+iouLk7PPvustmzZoubNmysnJ0cffvhhvlnTP5s6daomTJhQ9BcDAACUScyQlnFRUVFO62FhYTp+/Lj27t2r8PBwRxiVpHr16ikgIEB79+69bL8HDx5Udna2WrRo4dgWFBSk2rVrO7Xbtm2bunTpoipVqsjPz0/t2rWT9MftApJUqVIlde7cWe+++64k6YsvvlBWVpZ69uxZ4LnHjh2r9PR0x3LkyJHL1gsAAMouAmkZ5+7u7rRus9mUl5d3Tc595swZdejQQf7+/po3b562bt2qTz/9VJKUnZ3taDdo0CAtWLBA//3vf5WQkKBevXqpXLlyBfbr6ekpf39/pwUAAFy/CKTXqbp16+rIkSNOs4t79uzRqVOnVK9evcseX6NGDbm7u2vz5s2ObSdPntS+ffsc6//5z3/022+/adq0aWrTpo3q1KnjeKDpzzp16iQfHx/Nnj1by5Ytc7rMDwAAQCC9TrVv314NGzbUQw89pO3bt2vLli3q27ev2rVrp+jo6Mse7+vrq4EDB2rMmDFavXq1vv/+e8XFxcnF5X8fmSpVqsjDw0OvvvqqfvjhB33++eeaNGlSvr5cXV0VFxensWPHKjIyUi1btizWsQIAgLKNQHqdstls+uyzzxQYGKi2bduqffv2ql69uv71r38Vuo8XXnhBbdq0UZcuXdS+fXu1bt1azZo1c+yvUKGCEhMT9fHHH6tevXqaNm1agQ8rDRw4UNnZ2erfv/9Vjw0AAFxfbIb/mgfXwLp163THHXfoyJEjCgkJKdKxGRkZstvtmpY6TU9WfbKEKgQAAMXpwu/v9PT0yz4Pwtc+oURlZWXp119/VXx8vHr27FnkMPpnQwKHFGNlAACgtOCSPUrU/PnzVbVqVZ06dUrTp0+3uhwAAFAKcckepV5RpvwBAEDpUJTf38yQAgAAwFIEUgAAAFiKQAoAAABLEUgBAABgKQIpAAAALEUgBQAAgKUIpAAAALAUgRQAAACWIpACAADAUgRSAAAAWIpACgAAAEsRSAEAAGApAikAAAAsRSAFAACApQikAAAAsBSBFAAAAJYqkUBqs9m0ePHikuj6uhYTE6NRo0aVWP9xcXHq1q1bifV/QXx8vBo3blzi5wEAANeHIgfSY8eOafjw4apevbo8PT0VHh6uLl26aNWqVSVRX5FFRETo5ZdftrqMS0pKSpLNZtOpU6esLgUAAMBybkVpnJqaqlatWikgIEAvvPCCGjZsqJycHC1fvlxDhw7Vf/7zn5KqM5+cnBy5u7tfs/MVl5ycHKtLAAAAKFWKNEP66KOPymazacuWLerRo4dq1aql+vXr67HHHtOmTZsKPO7IkSOKjY1VQECAgoKC1LVrV6Wmpjr2b926VXfeeaeCg4Nlt9vVrl07bd++3akPm82m2bNn695775WPj4+mTJmS7zwxMTH68ccf9Y9//EM2m002m82xb+HChapfv748PT0VERGhmTNnXnKsFy47v/nmmwoPD1e5cuUUGxur9PT0q6p78ODBuu222yRJgYGBstlsiouLy3f+iRMnqkGDBvm2N27cWOPGjSuw7t27d+uee+6Rv7+//Pz81KZNGx08ePCibbOysjRixAhVrFhRXl5eat26tbZu3erYn5iYqICAAKdjFi9e7PS6StK0adMUEhIiPz8/DRw4UOfOnXPs+/e//y13d3cdO3bM6ZhRo0apTZs2BdaVkZHhtAAAgOtXoQPp77//rmXLlmno0KHy8fHJt/+vweWCnJwcdejQQX5+flq3bp02bNggX19fdezYUdnZ2ZKk06dPq1+/flq/fr02bdqkyMhIderUSadPn3bqKz4+Xt27d9euXbs0YMCAfOdatGiRKleurIkTJyotLU1paWmSpG3btik2Nla9e/fWrl27FB8fr3HjxikxMfGSYz5w4IA++ugjffHFF1q2bJl27NihRx991LH/SuqeMGGCFi5cKElKSUlRWlqaZs2ale/cAwYM0N69e50C4o4dO/Tdd9+pf//+F6336NGjatu2rTw9PbV69Wpt27ZNAwYM0Pnz5y/a/oknntDChQs1d+5cbd++XTVr1lSHDh30+++/X/J1+bOPPvpI8fHxeu655/Ttt98qLCxMb7zxhmN/27ZtVb16db3//vuObTk5OZo3b95F30NJmjp1qux2u2MJDw8vdD0AAKAMMoW0efNmI8ksWrTosm0lmU8//dQYY8z7779vateubfLy8hz7s7KyjLe3t1m+fPlFj8/NzTV+fn7miy++cOpz1KhRlz131apVzUsvveS07cEHHzR33nmn07YxY8aYevXqFdjP+PHjjaurq/npp58c25YuXWpcXFxMWlraVdW9Zs0aI8mcPHnSaXu7du3MyJEjHet33323GTJkiGN9+PDhJiYmpsCax44da6pVq2ays7Mvur9fv36ma9euxhhjMjMzjbu7u5k3b55jf3Z2tqlUqZKZPn26McaYhIQEY7fbnfr49NNPzZ8/Ni1btjSPPvqoU5sWLVqYRo0aOdaff/55U7duXcf6woULja+vr8nMzLxonefOnTPp6emO5ciRI0aSSU9PL3DsAACgdElPTy/07+9Cz5AaY64o8O7cuVMHDhyQn5+ffH195evrq6CgIJ07d85xKfmXX37R4MGDFRkZKbvdLn9/f2VmZurw4cNOfUVHR19RDXv37lWrVq2ctrVq1Ur79+9Xbm5ugcdVqVJFN910k2O9ZcuWysvLU0pKyjWpe/DgwZo/f77OnTun7OxsffjhhwXOKkpScnKy2rRpU6h7aw8ePKicnByn18Xd3V3NmzfX3r17C13j3r171aJFC6dtLVu2dFqPi4vTgQMHHLd1JCYmKjY29qIz7ZLk6ekpf39/pwUAAFy/Cv1QU2RkpGw2W5EfXMrMzFSzZs00b968fPsqVKggSerXr59+++03zZo1S1WrVpWnp6datmzpuKR/QUEBxiolXXeXLl3k6empTz/9VB4eHsrJydH9999fYHtvb+8rOk9BXFxc8v1D5EoeyqpYsaK6dOmihIQEVatWTUuXLlVSUlIxVQkAAMq6Qs+QBgUFqUOHDnr99dd15syZfPsL+gqjpk2bav/+/apYsaJq1qzptNjtdknShg0bNGLECHXq1Mnx4NGJEyeuaEAeHh75Zj3r1q2rDRs2OG3bsGGDatWqJVdX1wL7Onz4sH7++WfH+qZNm+Ti4qLatWtfVd0eHh6SdMnZWUlyc3NTv379lJCQoISEBPXu3fuSoTMqKkrr1q0rVGisUaOGPDw8nF6XnJwcbd26VfXq1ZP0xz8YTp8+7fR+JycnO/VTt25dbd682WnbxR5wGzRokP71r3/prbfeUo0aNfLNWAMAgBtXkZ6yf/3115Wbm6vmzZtr4cKF2r9/v/bu3atXXnkl32XaCx566CEFBwera9euWrdunQ4dOqSkpCSNGDFCP/30k6Q/Zl/ff/997d27V5s3b9ZDDz10xbN9ERER+ve//62jR486wuHo0aO1atUqTZo0Sfv27dPcuXP12muv6fHHH79kX15eXurXr5927typdevWacSIEYqNjVVoaOhV1V21alXZbDYtWbJEv/76qzIzMwtsO2jQIK1evVrLli275OV6SRo2bJgyMjLUu3dvffvtt9q/f7/ef/99xy0Gf+bj46MhQ4ZozJgxWrZsmfbs2aPBgwfr7NmzGjhwoCSpRYsWKleunP7v//5PBw8e1IcffpjvQbCRI0fq3XffVUJCgvbt26fx48dr9+7d+c7XoUMH+fv7a/LkyQU+lAUAAG5QRb1B9eeffzZDhw41VatWNR4eHuamm24y9957r1mzZo2jjf70UJMxxqSlpZm+ffua4OBg4+npaapXr24GDx7suMl1+/btJjo62nh5eZnIyEjz8ccf53s46a99FuSbb74xUVFRxtPT0+nhm08++cTUq1fPuLu7mypVqpgXXnjhkv2MHz/eNGrUyLzxxhumUqVKxsvLy9x///3m999/d7S5mronTpxoQkNDjc1mM/369TPG5H+o6YI2bdqY+vXrX3bsxhizc+dOc9ddd5ly5coZPz8/06ZNG3Pw4EFjjPNDTcYY89///tcMHz7c8b60atXKbNmyxam/Tz/91NSsWdN4e3ube+65x7z11lvmrx+bKVOmmODgYOPr62v69etnnnjiCaeHmi4YN26ccXV1NT///HOhxnJBUW6KBgAApUNRfn/bjLnCp5Wuc/Hx8Vq8eHG+S9TXmjFGkZGRevTRR/XYY49ZWsvVGjhwoH799Vd9/vnnRTouIyNDdrtd6enpPOAEAEAZUZTf30X6n5pwbf36669asGCBjh07VqYvc6enp2vXrl368MMPixxGAQDA9Y9AWopVrFhRwcHBeuuttxQYGGh1OVesa9eu2rJli/7+97/rzjvvtLocAABQynDJHqUel+wBACh7ivL7u0hP2QMAAADFjUAKAAAASxFIAQAAYCkCKQAAACxFIAUAAIClCKQAAACwFIEUAAAAliKQAgAAwFIEUgAAAFiKQAoAAABLEUgBAABgKQIpAAAALEUgBQAAgKUIpAAAALAUgRQAAACWIpDikmJiYjRq1CirywAAANcxAukNKC4uTjabTX//+9/z7Rs6dKhsNpvi4uIkSYsWLdKkSZMK1S/hFQAAXAkC6Q0qPDxcCxYs0H//+1/HtnPnzunDDz9UlSpVHNuCgoLk5+dnRYkAAOAGQSC9QTVt2lTh4eFatGiRY9uiRYtUpUoVNWnSxLHtr7Oeb7zxhiIjI+Xl5aWQkBDdf//9kv6YdV27dq1mzZolm80mm82mQ4cOqWbNmpoxY4bTuZOTk2Wz2XTgwIGSHSQAACgTCKQ3sAEDBighIcGx/u6776p///4Ftv/22281YsQITZw4USkpKVq2bJnatm0rSZo1a5ZatmypwYMHKy0tTWlpaapSpUq+c0hSQkKC2rZtq5o1a170PFlZWcrIyHBaAADA9YtAegN7+OGHtX79ev3444/68ccftWHDBj388MMFtj98+LB8fHx0zz33qGrVqmrSpIlGjBghSbLb7fLw8FC5cuUUGhqq0NBQubq6Ki4uTikpKdqyZYskKScnRx9++KEGDBhQ4HmmTp0qu93uWMLDw4t34AAAoFQhkN7AKlSooM6dOysxMVEJCQnq3LmzgoODC2x/5513qmrVqqpevbr69OmjefPm6ezZs5c8R6VKldS5c2e9++67kqQvvvhCWVlZ6tmzZ4HHjB07Vunp6Y7lyJEjVzZAAABQJhBIb3ADBgxQYmKi5s6de8lZS0ny8/PT9u3bNX/+fIWFhenZZ59Vo0aNdOrUqUseN2jQIMcDVAkJCerVq5fKlStXYHtPT0/5+/s7LQAA4PpFIL3BdezYUdnZ2crJyVGHDh0u297NzU3t27fX9OnT9d133yk1NVWrV6+WJHl4eCg3NzffMZ06dZKPj49mz56tZcuWXTb4AgCAG4ub1QXAWq6urtq7d6/j50tZsmSJfvjhB7Vt21aBgYH66quvlJeXp9q1a0uSIiIitHnzZqWmpsrX11dBQUFycXFx3Es6duxYRUZGqmXLliU+LgAAUHYwQ4pCXxYPCAjQokWLdPvtt6tu3br65z//qfnz56t+/fqSpMcff1yurq6qV6+eKlSooMOHDzuOHThwoLKzsy/5FD8AALgx2YwxxuoicP1bt26d7rjjDh05ckQhISFFOjYjI0N2u13p6encTwoAQBlRlN/fXLJHicrKytKvv/6q+Ph49ezZs8hhFAAAXP+4ZI8SNX/+fFWtWlWnTp3S9OnTrS4HAACUQlyyR6nHJXsAAMqeovz+ZoYUAAAAliKQAgAAwFIEUgAAAFiKQAoAAABLEUgBAABgKQIpAAAALEUgBQAAgKUIpAAAALAUgRQAAACWIpACAADAUgRSAAAAWIpACgAAAEsRSAEAAGApAikAAAAsRSAFAACApQikAAAAsBSBFCXKZrNp8eLFVpcBAABKMQIpikV8fLwaN25sdRkAAKAMIpACAADAUgTSG1BMTIyGDx+uUaNGKTAwUCEhIZozZ47OnDmj/v37y8/PTzVr1tTSpUslSUlJSbLZbFq1apWio6NVrlw53XrrrUpJSZEkJSYmasKECdq5c6dsNptsNpsSExMd5ztx4oS6d++ucuXKKTIyUp9//rkVwwYAAKUUgfQGNXfuXAUHB2vLli0aPny4hgwZop49e+rWW2/V9u3bddddd6lPnz46e/as45inn35aM2fO1Lfffis3NzcNGDBAktSrVy+NHj1a9evXV1pamtLS0tSrVy/HcRMmTFBsbKy+++47derUSQ899JB+//33AmvLyspSRkaG0wIAAK5fBNIbVKNGjfTMM88oMjJSY8eOlZeXl4KDgzV48GBFRkbq2Wef1W+//abvvvvOccyUKVPUrl071atXT0899ZQ2btyoc+fOydvbW76+vnJzc1NoaKhCQ0Pl7e3tOC4uLk4PPPCAatasqeeee06ZmZnasmVLgbVNnTpVdrvdsYSHh5foawEAAKxFIL1BRUVFOX52dXVV+fLl1bBhQ8e2kJAQSdLx48cvekxYWFi+/YU5l4+Pj/z9/S953NixY5Wenu5Yjhw5UogRAQCAssrN6gJgDXd3d6d1m83mtM1ms0mS8vLyLnrMxfYX5VyXOs7T01Oenp6X7RcAAFwfmCFFsfDw8FBubq7VZQAAgDKIQIpiERERoUOHDik5OVknTpxQVlaW1SUBAIAygkCKYtGjRw917NhRt912mypUqKD58+dbXRIAACgjbMYYY3URwKVkZGTIbrcrPT1d/v7+VpcDAAAKoSi/v5khBQAAgKUIpAAAALAUgRQAAACWIpACAADAUgRSAAAAWIpACgAAAEsRSAEAAGApAikAAAAsRSAFAACApQikAAAAsBSBFAAAAJYikAIAAMBSBFIAAABYikAKAAAASxFIAQAAYCkCKQAAACxFIAUAAIClCKQAAACwFIEUAAAAliKQAgAAwFIEUgAAAFiKQArLZGdnW10CAAAoBQikKDbvvfeeypcvr6ysLKft3bp1U58+fRQfH6/GjRvr7bffVrVq1eTl5WVRpQAAoDQhkKLY9OzZU7m5ufr8888d244fP64vv/xSAwYMkCQdOHBACxcu1KJFi5ScnHzRfrKyspSRkeG0AACA6xeBFMXG29tbDz74oBISEhzbPvjgA1WpUkUxMTGS/rhM/95776lJkyaKioq6aD9Tp06V3W53LOHh4deifAAAYBECKYrV4MGDtWLFCh09elSSlJiYqLi4ONlsNklS1apVVaFChUv2MXbsWKWnpzuWI0eOlHjdAADAOm5WF4DrS5MmTdSoUSO99957uuuuu7R79259+eWXjv0+Pj6X7cPT01Oenp4lWSYAAChFCKQodoMGDdLLL7+so0ePqn379lxyBwAAl8QlexS7Bx98UD/99JPmzJnjeJgJAACgIARSFDu73a4ePXrI19dX3bp1s7ocAABQyhFIUSKOHj2qhx56yOle0Pj4+AK/6gkAANy4uIcUxerkyZNKSkpSUlKS3njjDavLAQAAZQCBFMWqSZMmOnnypJ5//nnVrl3b6nIAAEAZQCBFsUpNTbW6BAAAUMZwDykAAAAsRSAFAACApQikAAAAsBSBFAAAAJbioSaUesYYSVJGRobFlQAAgMK68Hv7wu/xSyGQotT77bffJEnh4eEWVwIAAIrq9OnTstvtl2xDIEWpFxQUJEk6fPjwZT/Q15OMjAyFh4fryJEj8vf3t7qca4Zx31jjlm7csTNuxn29M8bo9OnTqlSp0mXbEkhR6rm4/HGrs91uv2H+EP+Zv78/476B3Kjjlm7csTPuG8uNNu7CTiTxUBMAAAAsRSAFAACApQikKPU8PT01fvx4eXp6Wl3KNcW4GfeN4kYdO+Nm3PgfmynMs/gAAABACWGGFAAAAJYikAIAAMBSBFIAAABYikAKAAAASxFIAQAAYCkCKUqF119/XREREfLy8lKLFi20ZcuWS7b/+OOPVadOHXl5ealhw4b66quvrlGlxaso4969e7d69OihiIgI2Ww2vfzyy9eu0GJWlHHPmTNHbdq0UWBgoAIDA9W+ffvLfj5Kq6KMe9GiRYqOjlZAQIB8fHzUuHFjvf/++9ew2uJV1D/jFyxYsEA2m03dunUr2QJLSFHGnZiYKJvN5rR4eXldw2qLT1Hf71OnTmno0KEKCwuTp6enatWqVSb/Xi/KuGNiYvK93zabTZ07d76GFZciBrDYggULjIeHh3n33XfN7t27zeDBg01AQID55ZdfLtp+w4YNxtXV1UyfPt3s2bPHPPPMM8bd3d3s2rXrGld+dYo67i1btpjHH3/czJ8/34SGhpqXXnrp2hZcTIo67gcffNC8/vrrZseOHWbv3r0mLi7O2O1289NPP13jyq9OUce9Zs0as2jRIrNnzx5z4MAB8/LLLxtXV1ezbNmya1z51Svq2C84dOiQuemmm0ybNm1M165dr02xxaio405ISDD+/v4mLS3NsRw7duwaV331ijrurKwsEx0dbTp16mTWr19vDh06ZJKSkkxycvI1rvzqFHXcv/32m9N7/f333xtXV1eTkJBwbQsvJQiksFzz5s3N0KFDHeu5ubmmUqVKZurUqRdtHxsbazp37uy0rUWLFuZvf/tbidZZ3Io67j+rWrVqmQ2kVzNuY4w5f/688fPzM3Pnzi2pEkvE1Y7bGGOaNGlinnnmmZIor0RdydjPnz9vbr31VvP222+bfv36lclAWtRxJyQkGLvdfo2qKzlFHffs2bNN9erVTXZ29rUqsURc7Z/xl156yfj5+ZnMzMySKrFU45I9LJWdna1t27apffv2jm0uLi5q3769vvnmm4se88033zi1l6QOHToU2L40upJxXw+KY9xnz55VTk6OgoKCSqrMYne14zbGaNWqVUpJSVHbtm1LstRid6VjnzhxoipWrKiBAwdeizKL3ZWOOzMzU1WrVlV4eLi6du2q3bt3X4tyi82VjPvzzz9Xy5YtNXToUIWEhKhBgwZ67rnnlJube63KvmrF8XfbO++8o969e8vHx6ekyizVCKSw1IkTJ5Sbm6uQkBCn7SEhITp27NhFjzl27FiR2pdGVzLu60FxjPvJJ59UpUqV8v2jpDS70nGnp6fL19dXHh4e6ty5s1599VXdeeedJV1usbqSsa9fv17vvPOO5syZcy1KLBFXMu7atWvr3Xff1WeffaYPPvhAeXl5uvXWW/XTTz9di5KLxZWM+4cfftAnn3yi3NxcffXVVxo3bpxmzpypyZMnX4uSi8XV/t22ZcsWff/99xo0aFBJlVjquVldAAAU1rRp07RgwQIlJSWV2Yc9isLPz0/JycnKzMzUqlWr9Nhjj6l69eqKiYmxurQSc/r0afXp00dz5sxRcHCw1eVcUy1btlTLli0d67feeqvq1q2rN998U5MmTbKwspKVl5enihUr6q233pKrq6uaNWumo0eP6oUXXtD48eOtLu+aeOedd9SwYUM1b97c6lIsQyCFpYKDg+Xq6qpffvnFafsvv/yi0NDQix4TGhpapPal0ZWM+3pwNeOeMWOGpk2bpq+//lpRUVElWWaxu9Jxu7i4qGbNmpKkxo0ba+/evZo6dWqZCqRFHfvBgweVmpqqLl26OLbl5eVJktzc3JSSkqIaNWqUbNHFoDj+jLu7u6tJkyY6cOBASZRYIq5k3GFhYXJ3d5erq6tjW926dXXs2DFlZ2fLw8OjRGsuDlfzfp85c0YLFizQxIkTS7LEUo9L9rCUh4eHmjVrplWrVjm25eXladWqVU4zBX/WsmVLp/aStHLlygLbl0ZXMu7rwZWOe/r06Zo0aZKWLVum6Ojoa1FqsSqu9zsvL09ZWVklUWKJKerY69Spo127dik5Odmx3HvvvbrtttuUnJys8PDwa1n+FSuO9zw3N1e7du1SWFhYSZVZ7K5k3K1atdKBAwcc//CQpH379iksLKxMhFHp6t7vjz/+WFlZWXr44YdLuszSzeqnqoAFCxYYT09Pk5iYaPbs2WMeeeQRExAQ4Pi6kz59+pinnnrK0X7Dhg3Gzc3NzJgxw+zdu9eMHz++zH7tU1HGnZWVZXbs2GF27NhhwsLCzOOPP2527Nhh9u/fb9UQrkhRxz1t2jTj4eFhPvnkE6evSDl9+rRVQ7giRR33c889Z1asWGEOHjxo9uzZY2bMmGHc3NzMnDlzrBrCFSvq2P+qrD5lX9RxT5gwwSxfvtwcPHjQbNu2zfTu3dt4eXmZ3bt3WzWEK1LUcR8+fNj4+fmZYcOGmZSUFLNkyRJTsWJFM3nyZKuGcEWu9HPeunVr06tXr2tdbqlDIEWp8Oqrr5oqVaoYDw8P07x5c7Np0ybHvnbt2pl+/fo5tf/oo49MrVq1jIeHh6lfv7758ssvr3HFxaMo4z506JCRlG9p167dtS/8KhVl3FWrVr3ouMePH3/tC79KRRn3008/bWrWrGm8vLxMYGCgadmypVmwYIEFVRePov4Z/7OyGkiNKdq4R40a5WgbEhJiOnXqZLZv325B1VevqO/3xo0bTYsWLYynp6epXr26mTJlijl//vw1rvrqFXXc//nPf4wks2LFimtcaeljM8YYiyZnAQAAAO4hBQAAgLUIpAAAALAUgRQAAACWIpACAADAUgRSAAAAWIpACgAAAEsRSAEAAGApAikAAAAsRSAFAACApQikAAAAsBSBFAAAAJb6f8zZfj4ZgI5tAAAAAElFTkSuQmCC\n"},"metadata":{}}]},{"source":"Apparently, hr and workingday are the most important features according to rf. The importances of these two features add up to more than 90%!","metadata":{},"cell_type":"markdown","id":"f33f2202-53c4-4eee-bc39-c962dfdaeffc"},{"source":"**AdaBoost classifier**\n\nWe'll revisit the Indian Liver Patient dataset which was introduced in a previous chapter. Our task is to predict whether a patient suffers from a liver disease using 10 features including Albumin, age and gender. However, this time, we'll be training an AdaBoost ensemble to perform the classification task. In addition, given that this dataset is imbalanced, you'll be using the ROC AUC score as a metric instead of accuracy.\n\nAs a first step, you'll start by instantiating an AdaBoost classifier.","metadata":{},"cell_type":"markdown","id":"34a4bc83-a16e-4b23-afdb-3833113d1fc1"},{"source":"# Import DecisionTreeClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Import AdaBoostClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\n# Instantiate dt\ndt = DecisionTreeClassifier(max_depth=2, random_state=1)\n\n# Instantiate ada\nada = AdaBoostClassifier(base_estimator=dt, n_estimators=180, random_state=1)","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Import DecisionTreeClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Import AdaBoostClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\n# Instantiate dt\ndt = DecisionTreeClassifier(max_depth=2, random_state=1)\n\n# Instantiate ada\nada = AdaBoostClassifier(base_estimator=dt, n_estimators=180, random_state=1)"},"cell_type":"code","id":"6ae3737c-fc24-4896-b4b9-1d92de73cf68","execution_count":363,"outputs":[]},{"source":"Now that we've instantiated the AdaBoost classifier ada, it's time train it. We will also predict the probabilities of obtaining the positive class in the test set. This can be done as follows:oOnce the classifier ada is trained, call the .predict_proba() method by passing X_test as a parameter and extract these probabilities by slicing all the values in the second column","metadata":{},"cell_type":"markdown","id":"11b32b87-8a57-4973-a3ed-d855195b93b7"},{"source":"# Fit ada to the training set\nada.fit(Xl_train_std, yl_train)\n\n# Compute the probabilities of obtaining the positive class\ny_pred_proba = ada.predict_proba(Xl_test_std)[:, 1]","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Fit ada to the training set\nada.fit(Xl_train_std, yl_train)\n\n# Compute the probabilities of obtaining the positive class\ny_pred_proba = ada.predict_proba(Xl_test_std)[:, 1]"},"cell_type":"code","id":"a2349fe6-e1f1-4006-8f4e-2e2442cd9b03","execution_count":364,"outputs":[]},{"source":"**Evaluate the AdaBoost classifier**\n\nNow that we're done training ada and predicting the probabilities of obtaining the positive class in the test set, it's time to evaluate ada's ROC AUC score, the ROC AUC score of a binary classifier can be determined using the roc_auc_score() function from sklearn.metrics.","metadata":{},"cell_type":"markdown","id":"a600fb97-2908-42dc-bbd5-03150657cadd"},{"source":"# Import roc_auc_score\nfrom sklearn.metrics import roc_auc_score\n\n# Evaluate test-set roc_auc_score\nada_roc_auc = roc_auc_score(yl_test, y_pred_proba)\n\n# Print roc_auc_score\nprint('ROC AUC score: {:.2f}'.format(ada_roc_auc))","metadata":{"executionTime":25,"lastSuccessfullyExecutedCode":"# Import roc_auc_score\nfrom sklearn.metrics import roc_auc_score\n\n# Evaluate test-set roc_auc_score\nada_roc_auc = roc_auc_score(yl_test, y_pred_proba)\n\n# Print roc_auc_score\nprint('ROC AUC score: {:.2f}'.format(ada_roc_auc))"},"cell_type":"code","id":"cd16d2a3-7c1a-4952-98fb-454c03e3bbb1","execution_count":365,"outputs":[{"output_type":"stream","name":"stdout","text":"ROC AUC score: 0.63\n"}]},{"source":"**Gradient Boosting regressor**\n\nWe'll now revisit the Bike Sharing Demand dataset. Recall that our task is to predict the bike rental demand using historical weather data from the Capital Bikeshare program in Washington, D.C.. For this purpose, we'll be using a gradient boosting regressor.","metadata":{},"cell_type":"markdown","id":"3be7f499-2bf4-4251-9a8c-1e82862f90e6"},{"source":"# Import GradientBoostingRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\n# Instantiate gb\ngb = GradientBoostingRegressor(max_depth=6, \n            n_estimators=200,\n            random_state=2)","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Import GradientBoostingRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\n# Instantiate gb\ngb = GradientBoostingRegressor(max_depth=6, \n            n_estimators=200,\n            random_state=2)"},"cell_type":"code","id":"c7e3dd41-9fc3-4b5c-b0de-be3de9b52e9d","execution_count":366,"outputs":[]},{"source":"# Fit gb to the training set\ngb.fit(Xb_train, yb_train)\n# Predict test set labels\nyb_pred = gb.predict(Xb_test)","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Fit gb to the training set\ngb.fit(Xb_train, yb_train)\n# Predict test set labels\nyb_pred = gb.predict(Xb_test)"},"cell_type":"code","id":"dcbdda35-5b9a-4695-a842-75160f7d2aca","execution_count":367,"outputs":[]},{"source":"# Compute MSE\nmse_test = MSE(yb_test, yb_pred)\n\n# Compute RMSE\nrmse_test = mse_test**(1/2)\n\n# Print RMSE\nprint('Test set RMSE of gb: {:.3f}'.format(rmse_test))","metadata":{"executionTime":25,"lastSuccessfullyExecutedCode":"# Compute MSE\nmse_test = MSE(yb_test, yb_pred)\n\n# Compute RMSE\nrmse_test = mse_test**(1/2)\n\n# Print RMSE\nprint('Test set RMSE of gb: {:.3f}'.format(rmse_test))"},"cell_type":"code","id":"c2956392-d863-4c07-843b-347e28c6971d","execution_count":368,"outputs":[{"output_type":"stream","name":"stdout","text":"Test set RMSE of gb: 44.793\n"}]},{"source":"**Stochastic Gradient Boosting**","metadata":{},"cell_type":"markdown","id":"3f9339ee-2c8b-4e8f-9b2e-8fa1039919b8"},{"source":"# Import GradientBoostingRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\n\n# Instantiate sgbr\nsgbr = GradientBoostingRegressor(max_depth=6, \n            subsample=0.90,\n            max_features=0.75,\n            n_estimators=200,\n            random_state=2)","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Import GradientBoostingRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\n\n# Instantiate sgbr\nsgbr = GradientBoostingRegressor(max_depth=6, \n            subsample=0.90,\n            max_features=0.75,\n            n_estimators=200,\n            random_state=2)"},"cell_type":"code","id":"85439180-3939-49b7-a180-c5de0cb4560a","execution_count":369,"outputs":[]},{"source":"# Fit sgbr to the training set\nsgbr.fit(Xb_train, yb_train)\n\n# Predict test set labels\nyb_pred = sgbr.predict(Xb_test)","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Fit sgbr to the training set\nsgbr.fit(Xb_train, yb_train)\n\n# Predict test set labels\nyb_pred = sgbr.predict(Xb_test)"},"cell_type":"code","id":"fc9e2f96-2e7e-4c9c-be31-5ea3e5157bc0","execution_count":370,"outputs":[]},{"source":"# Compute test set MSE\nmse_test = MSE(yb_test, yb_pred)\n\n# Compute test set RMSE\nrmse_test = mse_test**(1/2)\n\n# Print rmse_test\nprint('Test set RMSE of sgbr: {:.3f}'.format(rmse_test))","metadata":{"executionTime":23,"lastSuccessfullyExecutedCode":"# Compute test set MSE\nmse_test = MSE(yb_test, yb_pred)\n\n# Compute test set RMSE\nrmse_test = mse_test**(1/2)\n\n# Print rmse_test\nprint('Test set RMSE of sgbr: {:.3f}'.format(rmse_test))"},"cell_type":"code","id":"856d3980-b386-45b0-af81-921bada8e574","execution_count":371,"outputs":[{"output_type":"stream","name":"stdout","text":"Test set RMSE of sgbr: 43.881\n"}]},{"source":"**Tuning a CART's Hyperparameters**","metadata":{},"cell_type":"markdown","id":"445771af-ae8c-4bdb-bdae-c07037a7a317"},{"source":"**Tree hyperparameters**\n\nIn the following we'll revisit the Indian Liver Patient dataset. Our task is to tune the hyperparameters of a classification tree. Given that this dataset is imbalanced, we'll be using the ROC AUC score as a metric instead of accuracy.\n\nWe have instantiated a DecisionTreeClassifier and assigned to dt with sklearn's default hyperparameters. We can inspect the hyperparameters of dt in our console.","metadata":{},"cell_type":"markdown","id":"2f9ea7df-85f1-4dd0-a84b-ed3bde048eaf"},{"source":"# Instantiate dt\ndtl = DecisionTreeClassifier(min_samples_leaf=0.13, random_state=1)\n\n# Fit dt to the training set\ndtl.fit(Xl_train_std, yl_train)    \n   \n# Predict y_pred\nyl_pred_proba = dtl.predict_proba(Xl_test_std)[:,1]\n\n# Compute test_roc_auc\ntest_roc_auc = roc_auc_score(yl_test, yl_pred_proba)\n\n# Print test_roc_auc\nprint('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))","metadata":{"executionTime":49,"lastSuccessfullyExecutedCode":"# Instantiate dt\ndtl = DecisionTreeClassifier(min_samples_leaf=0.13, random_state=1)\n\n# Fit dt to the training set\ndtl.fit(Xl_train_std, yl_train)    \n   \n# Predict y_pred\nyl_pred_proba = dtl.predict_proba(Xl_test_std)[:,1]\n\n# Compute test_roc_auc\ntest_roc_auc = roc_auc_score(yl_test, yl_pred_proba)\n\n# Print test_roc_auc\nprint('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))"},"cell_type":"code","id":"91066ecd-623a-4dac-b4f4-3e7031c101db","execution_count":385,"outputs":[{"output_type":"stream","name":"stdout","text":"Test set ROC AUC score: 0.734\n"}]},{"source":"# Print out 'dt's hyperparameters\nprint(dtl.get_params())","metadata":{"executionTime":38,"lastSuccessfullyExecutedCode":"# Print out 'dt's hyperparameters\nprint(dtl.get_params())"},"cell_type":"code","id":"c11a5702-960e-49a2-b641-b06427629050","execution_count":386,"outputs":[{"output_type":"stream","name":"stdout","text":"{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 0.13, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 1, 'splitter': 'best'}\n"}]},{"source":"**Search for the optimal tree**\n\nWe'll perform grid search using 5-fold cross validation to find dt's optimal hyperparameters. Note that because grid search is an exhaustive process, it may take a lot time to train the model. ","metadata":{},"cell_type":"markdown","id":"06f9574a-20cf-48f8-9ff9-088a16297e56"},{"source":"# Define params_dt\nparams_dt = {'max_depth': [2, 3, 4], 'min_samples_leaf': [0.13, 0.14, 0.16, 0.18]}\n\n# Import GridSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\n# Instantiate grid_dt\ngrid_dt = GridSearchCV(estimator=dtl,\n                       param_grid=params_dt,\n                       scoring='roc_auc',\n                       cv=5,\n                       n_jobs=-1)\n\n# Fit 'grid_dt' to the training data\ngrid_dt.fit(Xl_train_std, yl_train)\n","metadata":{"executionTime":35,"lastSuccessfullyExecutedCode":"# Define params_dt\nparams_dt = {'max_depth': [2, 3, 4], 'min_samples_leaf': [0.13, 0.14, 0.16, 0.18]}\n\n# Import GridSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\n# Instantiate grid_dt\ngrid_dt = GridSearchCV(estimator=dtl,\n                       param_grid=params_dt,\n                       scoring='roc_auc',\n                       cv=5,\n                       n_jobs=-1)\n\n# Fit 'grid_dt' to the training data\ngrid_dt.fit(Xl_train_std, yl_train)\n"},"cell_type":"code","id":"e8e9fe2b-9cc3-4529-854d-d3d35bd6ec87","execution_count":387,"outputs":[{"output_type":"execute_result","execution_count":387,"data":{"text/plain":"GridSearchCV(cv=5,\n             estimator=DecisionTreeClassifier(min_samples_leaf=0.13,\n                                              random_state=1),\n             n_jobs=-1,\n             param_grid={'max_depth': [2, 3, 4],\n                         'min_samples_leaf': [0.13, 0.14, 0.16, 0.18]},\n             scoring='roc_auc')","text/html":"<style>#sk-container-id-28 {color: black;background-color: white;}#sk-container-id-28 pre{padding: 0;}#sk-container-id-28 div.sk-toggleable {background-color: white;}#sk-container-id-28 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-28 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-28 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-28 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-28 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-28 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-28 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-28 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-28 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-28 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-28 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-28 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-28 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-28 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-28 div.sk-item {position: relative;z-index: 1;}#sk-container-id-28 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-28 div.sk-item::before, #sk-container-id-28 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-28 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-28 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-28 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-28 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-28 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-28 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-28 div.sk-label-container {text-align: center;}#sk-container-id-28 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-28 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-28\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n             estimator=DecisionTreeClassifier(min_samples_leaf=0.13,\n                                              random_state=1),\n             n_jobs=-1,\n             param_grid={&#x27;max_depth&#x27;: [2, 3, 4],\n                         &#x27;min_samples_leaf&#x27;: [0.13, 0.14, 0.16, 0.18]},\n             scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n             estimator=DecisionTreeClassifier(min_samples_leaf=0.13,\n                                              random_state=1),\n             n_jobs=-1,\n             param_grid={&#x27;max_depth&#x27;: [2, 3, 4],\n                         &#x27;min_samples_leaf&#x27;: [0.13, 0.14, 0.16, 0.18]},\n             scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(min_samples_leaf=0.13, random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(min_samples_leaf=0.13, random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}]},{"source":"**Evaluate the optimal tree**\n\nWe'll evaluate the test set ROC AUC score of grid_dt's optimal model.\n\nIn order to do so, we will first determine the probability of obtaining the positive label for each test set observation. We can use the method predict_proba() of an sklearn classifier to compute a 2D array containing the probabilities of the negative and positive class-labels respectively along columns.","metadata":{},"cell_type":"markdown","id":"b354b1bd-58e1-4942-9eff-01b2ddbbd75c"},{"source":"# Extract the best estimator\nbest_model = grid_dt.best_estimator_\n\n# Predict the test set probabilities of the positive class\ny_pred_proba = best_model.predict_proba(Xl_test_std)[:,1]\n\n# Compute test_roc_auc\ntest_roc_auc = roc_auc_score(yl_test, y_pred_proba)\n\n# Print test_roc_auc\nprint('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))","metadata":{"executionTime":42,"lastSuccessfullyExecutedCode":"# Extract the best estimator\nbest_model = grid_dt.best_estimator_\n\n# Predict the test set probabilities of the positive class\ny_pred_proba = best_model.predict_proba(Xl_test_std)[:,1]\n\n# Compute test_roc_auc\ntest_roc_auc = roc_auc_score(yl_test, y_pred_proba)\n\n# Print test_roc_auc\nprint('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))"},"cell_type":"code","id":"e58c27c3-e1a0-4b09-b111-caeceb6b7d6c","execution_count":388,"outputs":[{"output_type":"stream","name":"stdout","text":"Test set ROC AUC score: 0.731\n"}]},{"source":"# Extract best hyperparameters from 'grid_dt'\nbest_hyperparams = grid_dt.best_params_\nprint('Best hyerparameters:\\n', best_hyperparams)","metadata":{"executionTime":46,"lastSuccessfullyExecutedCode":"# Extract best hyperparameters from 'grid_dt'\nbest_hyperparams = grid_dt.best_params_\nprint('Best hyerparameters:\\n', best_hyperparams)"},"cell_type":"code","id":"2e373733-b698-466b-8cf4-4eb49de93a16","execution_count":389,"outputs":[{"output_type":"stream","name":"stdout","text":"Best hyerparameters:\n {'max_depth': 3, 'min_samples_leaf': 0.14}\n"}]},{"source":"**Random forests hyperparameters**\n\nWe'll be revisiting the Bike Sharing Demand dataset. Recall that our task is to predict the bike rental demand using historical weather data from the Capital Bikeshare program in Washington, D.C.. For this purpose, you'll be tuning the hyperparameters of a Random Forests regressor.\n\nWe have instantiated a RandomForestRegressor called rfb using sklearn's default hyperparameters. ","metadata":{},"cell_type":"markdown","id":"ef1125df-0e07-41d8-81ad-598d7cab7b13"},{"source":"# Print out 'dt's hyperparameters\nprint(rfb.get_params())","metadata":{"executionTime":20,"lastSuccessfullyExecutedCode":"# Print out 'dt's hyperparameters\nprint(rfb.get_params())"},"cell_type":"code","id":"815ee516-3212-425d-904e-c337544a8951","execution_count":377,"outputs":[{"output_type":"stream","name":"stdout","text":"{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 25, 'n_jobs': None, 'oob_score': False, 'random_state': 2, 'verbose': 0, 'warm_start': False}\n"}]},{"source":"# Define the dictionary 'params_rf'\nparams_rf = {'n_estimators': [100, 350, 500],'max_features': ['log2', 'auto', 'sqrt'], 'min_samples_leaf': [2, 10, 30]}","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Define the dictionary 'params_rf'\nparams_rf = {'n_estimators': [100, 350, 500],'max_features': ['log2', 'auto', 'sqrt'], 'min_samples_leaf': [2, 10, 30]}"},"cell_type":"code","id":"718e6eea-a6b8-4f3b-9315-c245ecdd1ae4","execution_count":378,"outputs":[]},{"source":"We'll perform grid search using 3-fold cross validation to find rf's optimal hyperparameters. To evaluate each model in the grid, you'll be using the negative mean squared error metric.","metadata":{},"cell_type":"markdown","id":"55faa89c-557d-4c8c-9d5e-4af167a5f7dc"},{"source":"# Import GridSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\n# Instantiate grid_rf\ngrid_rf = GridSearchCV(estimator=rfb,\n                       param_grid=params_rf,\n                       scoring='neg_mean_squared_error',\n                       cv=5,\n                       verbose=1,\n                       n_jobs=-1)\n\n# Fit 'grid_rf' to the training data\ngrid_rf.fit(Xb_train, yb_train)","metadata":{"executionTime":32377,"lastSuccessfullyExecutedCode":"# Import GridSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\n# Instantiate grid_rf\ngrid_rf = GridSearchCV(estimator=rfb,\n                       param_grid=params_rf,\n                       scoring='neg_mean_squared_error',\n                       cv=5,\n                       verbose=1,\n                       n_jobs=-1)\n\n# Fit 'grid_rf' to the training data\ngrid_rf.fit(Xb_train, yb_train)"},"cell_type":"code","id":"f9146b11-b0f4-4e1b-b3c8-62b687b0d5db","execution_count":382,"outputs":[{"output_type":"stream","name":"stdout","text":"Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"},{"output_type":"execute_result","execution_count":382,"data":{"text/plain":"GridSearchCV(cv=5,\n             estimator=RandomForestRegressor(n_estimators=25, random_state=2),\n             n_jobs=-1,\n             param_grid={'max_features': ['log2', 'auto', 'sqrt'],\n                         'min_samples_leaf': [2, 10, 30],\n                         'n_estimators': [100, 350, 500]},\n             scoring='neg_mean_squared_error', verbose=1)","text/html":"<style>#sk-container-id-27 {color: black;background-color: white;}#sk-container-id-27 pre{padding: 0;}#sk-container-id-27 div.sk-toggleable {background-color: white;}#sk-container-id-27 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-27 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-27 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-27 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-27 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-27 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-27 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-27 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-27 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-27 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-27 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-27 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-27 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-27 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-27 div.sk-item {position: relative;z-index: 1;}#sk-container-id-27 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-27 div.sk-item::before, #sk-container-id-27 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-27 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-27 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-27 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-27 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-27 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-27 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-27 div.sk-label-container {text-align: center;}#sk-container-id-27 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-27 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-27\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n             estimator=RandomForestRegressor(n_estimators=25, random_state=2),\n             n_jobs=-1,\n             param_grid={&#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;auto&#x27;, &#x27;sqrt&#x27;],\n                         &#x27;min_samples_leaf&#x27;: [2, 10, 30],\n                         &#x27;n_estimators&#x27;: [100, 350, 500]},\n             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n             estimator=RandomForestRegressor(n_estimators=25, random_state=2),\n             n_jobs=-1,\n             param_grid={&#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;auto&#x27;, &#x27;sqrt&#x27;],\n                         &#x27;min_samples_leaf&#x27;: [2, 10, 30],\n                         &#x27;n_estimators&#x27;: [100, 350, 500]},\n             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=25, random_state=2)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=25, random_state=2)</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}]},{"source":"# Extract the best estimator\nbest_model = grid_rf.best_estimator_\n\n# Predict test set labels\nyb_pred = best_model.predict(Xb_test)\n\n# Compute rmse_test\nrmse_test = (MSE(yb_test, yb_pred))**(1/2)\n\n# Print rmse_test\nprint('Test RMSE of best model: {:.3f}'.format(rmse_test)) ","metadata":{"executionTime":63,"lastSuccessfullyExecutedCode":"# Extract the best estimator\nbest_model = grid_rf.best_estimator_\n\n# Predict test set labels\nyb_pred = best_model.predict(Xb_test)\n\n# Compute rmse_test\nrmse_test = (MSE(yb_test, yb_pred))**(1/2)\n\n# Print rmse_test\nprint('Test RMSE of best model: {:.3f}'.format(rmse_test)) "},"cell_type":"code","id":"9a2a4d51-6bec-4f09-a7ac-2ababdc54329","execution_count":390,"outputs":[{"output_type":"stream","name":"stdout","text":"Test RMSE of best model: 50.786\n"}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}